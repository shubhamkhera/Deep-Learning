{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d26c67",
   "metadata": {},
   "source": [
    "# Day 3: 3.2\n",
    "\n",
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "## Here we are creating an DeepLearning model that can predict wether the customer is a good/bad on the basis of age and salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e820219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c69da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"03_Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79233b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b4597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c4974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            0\n",
       "Gender             0\n",
       "Age                0\n",
       "EstimatedSalary    0\n",
       "Purchased          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2e23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c789e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12c22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules of Classification for ML:\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 1d NP array\n",
    "# 6. Normalization of features is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea641df",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c650cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6870a0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8e1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Check the quality of model\n",
    "# 1. CHeck whether the model is a generalized or not\n",
    "print(log_model.score(X_train,y_train))\n",
    "print(log_model.score(X_test,y_test))\n",
    "\n",
    "# 2. CHeck the quality of model with respect to CL\n",
    "# SL = 0.1\n",
    "# CL = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e8a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for Deep Learning\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 2d NP array\n",
    "# 6. Features must be NORMALIZED\n",
    "# 7. For Binary Classification, label must be represented as 0 / 1 (pd.replace)\n",
    "# 8. For Multi-class classification, label must be  DISCRETE NUMERICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6c53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,[4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844e5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rbFeatures=RobustScaler()\n",
    "features = rbFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a613aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d49961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "# Step1 : Architect the model\n",
    "# step 1.1: Create a Sequential Model\n",
    "\n",
    "seq_model = tf.keras.Sequential()\n",
    "\n",
    "# Step 1.2: Create Dense Layer\n",
    "# units = No. of neurons in Hidden Layer\n",
    "# activation = Which Activation Function to Apply\n",
    "# input_shape = Number of colums in FeatureArray\n",
    "\n",
    "\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1), input_shape = (2,)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e67b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "# Step2: Compile the mode:\n",
    "\n",
    "seq_model.compile(optimizer=\"sgd\", loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c604fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4fe5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,cl):\n",
    "        super(MyThresholdCallBack, self).__init__()\n",
    "        self.cl = cl\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_score = logs[\"val_accuracy\"]\n",
    "        train_score = logs[\"accuracy\"]\n",
    "        \n",
    "        if test_score > train_score and test_score > self.cl:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa474aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 0.7087 - accuracy: 0.3125 - val_loss: 0.7022 - val_accuracy: 0.3125\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6998 - accuracy: 0.4594 - val_loss: 0.6947 - val_accuracy: 0.5375\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6930 - accuracy: 0.5688 - val_loss: 0.6892 - val_accuracy: 0.5750\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6876 - accuracy: 0.6250 - val_loss: 0.6845 - val_accuracy: 0.6875\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6831 - accuracy: 0.6594 - val_loss: 0.6804 - val_accuracy: 0.7000\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.6812 - val_loss: 0.6769 - val_accuracy: 0.7125\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6759 - accuracy: 0.7188 - val_loss: 0.6738 - val_accuracy: 0.7375\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.7344 - val_loss: 0.6709 - val_accuracy: 0.7375\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6702 - accuracy: 0.7281 - val_loss: 0.6683 - val_accuracy: 0.7375\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6676 - accuracy: 0.7125 - val_loss: 0.6658 - val_accuracy: 0.7250\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6653 - accuracy: 0.7000 - val_loss: 0.6634 - val_accuracy: 0.7000\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6630 - accuracy: 0.6812 - val_loss: 0.6612 - val_accuracy: 0.6875\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6608 - accuracy: 0.6781 - val_loss: 0.6590 - val_accuracy: 0.6875\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6586 - accuracy: 0.6750 - val_loss: 0.6568 - val_accuracy: 0.6750\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6566 - accuracy: 0.6656 - val_loss: 0.6548 - val_accuracy: 0.6750\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6546 - accuracy: 0.6625 - val_loss: 0.6527 - val_accuracy: 0.6750\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6527 - accuracy: 0.6625 - val_loss: 0.6507 - val_accuracy: 0.6750\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6508 - accuracy: 0.6625 - val_loss: 0.6487 - val_accuracy: 0.6750\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6488 - accuracy: 0.6625 - val_loss: 0.6467 - val_accuracy: 0.6750\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6469 - accuracy: 0.6625 - val_loss: 0.6447 - val_accuracy: 0.6750\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6450 - accuracy: 0.6625 - val_loss: 0.6428 - val_accuracy: 0.6750\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6432 - accuracy: 0.6625 - val_loss: 0.6408 - val_accuracy: 0.6750\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.6625 - val_loss: 0.6388 - val_accuracy: 0.6750\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6394 - accuracy: 0.6625 - val_loss: 0.6369 - val_accuracy: 0.6750\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6375 - accuracy: 0.6625 - val_loss: 0.6349 - val_accuracy: 0.6750\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6356 - accuracy: 0.6625 - val_loss: 0.6329 - val_accuracy: 0.6750\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6337 - accuracy: 0.6625 - val_loss: 0.6309 - val_accuracy: 0.6750\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6317 - accuracy: 0.6656 - val_loss: 0.6289 - val_accuracy: 0.6750\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6298 - accuracy: 0.6719 - val_loss: 0.6268 - val_accuracy: 0.6750\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6278 - accuracy: 0.6719 - val_loss: 0.6247 - val_accuracy: 0.6750\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6258 - accuracy: 0.6687 - val_loss: 0.6226 - val_accuracy: 0.6750\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6238 - accuracy: 0.6687 - val_loss: 0.6205 - val_accuracy: 0.6750\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.6687 - val_loss: 0.6183 - val_accuracy: 0.6750\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6196 - accuracy: 0.6750 - val_loss: 0.6161 - val_accuracy: 0.6750\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6175 - accuracy: 0.6750 - val_loss: 0.6138 - val_accuracy: 0.6750\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6152 - accuracy: 0.6812 - val_loss: 0.6115 - val_accuracy: 0.6875\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.6130 - accuracy: 0.6844 - val_loss: 0.6091 - val_accuracy: 0.7000\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6107 - accuracy: 0.6844 - val_loss: 0.6066 - val_accuracy: 0.7000\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6084 - accuracy: 0.6875 - val_loss: 0.6041 - val_accuracy: 0.7000\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6059 - accuracy: 0.6906 - val_loss: 0.6016 - val_accuracy: 0.7125\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6034 - accuracy: 0.6969 - val_loss: 0.5990 - val_accuracy: 0.7125\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6009 - accuracy: 0.6969 - val_loss: 0.5963 - val_accuracy: 0.7125\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5983 - accuracy: 0.6969 - val_loss: 0.5935 - val_accuracy: 0.7125\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5956 - accuracy: 0.6969 - val_loss: 0.5907 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5929 - accuracy: 0.7000 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5901 - accuracy: 0.7031 - val_loss: 0.5848 - val_accuracy: 0.7500\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5871 - accuracy: 0.7063 - val_loss: 0.5817 - val_accuracy: 0.7500\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5842 - accuracy: 0.7156 - val_loss: 0.5785 - val_accuracy: 0.7500\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5811 - accuracy: 0.7219 - val_loss: 0.5752 - val_accuracy: 0.7500\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.5779 - accuracy: 0.7312 - val_loss: 0.5718 - val_accuracy: 0.7500\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5746 - accuracy: 0.7312 - val_loss: 0.5683 - val_accuracy: 0.7625\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.7437 - val_loss: 0.5647 - val_accuracy: 0.7625\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5679 - accuracy: 0.7469 - val_loss: 0.5610 - val_accuracy: 0.7750\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5644 - accuracy: 0.7531 - val_loss: 0.5573 - val_accuracy: 0.7750\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5608 - accuracy: 0.7563 - val_loss: 0.5534 - val_accuracy: 0.7875\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5571 - accuracy: 0.7719 - val_loss: 0.5494 - val_accuracy: 0.7875\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7750 - val_loss: 0.5453 - val_accuracy: 0.7875\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5495 - accuracy: 0.7875 - val_loss: 0.5411 - val_accuracy: 0.7875\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5455 - accuracy: 0.7844 - val_loss: 0.5368 - val_accuracy: 0.7875\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5414 - accuracy: 0.7937 - val_loss: 0.5324 - val_accuracy: 0.7750\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5372 - accuracy: 0.7969 - val_loss: 0.5279 - val_accuracy: 0.7875\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.8062 - val_loss: 0.5232 - val_accuracy: 0.8000\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5285 - accuracy: 0.8188 - val_loss: 0.5185 - val_accuracy: 0.8000\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5240 - accuracy: 0.8250 - val_loss: 0.5136 - val_accuracy: 0.8125\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.8281 - val_loss: 0.5086 - val_accuracy: 0.8250\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.8250 - val_loss: 0.5036 - val_accuracy: 0.8500\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5101 - accuracy: 0.8281 - val_loss: 0.4984 - val_accuracy: 0.8625\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5052 - accuracy: 0.8375 - val_loss: 0.4932 - val_accuracy: 0.8625\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5003 - accuracy: 0.8438 - val_loss: 0.4879 - val_accuracy: 0.8625\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4953 - accuracy: 0.8594 - val_loss: 0.4826 - val_accuracy: 0.8625\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4902 - accuracy: 0.8687 - val_loss: 0.4772 - val_accuracy: 0.8625\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4852 - accuracy: 0.8687 - val_loss: 0.4717 - val_accuracy: 0.8750\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4800 - accuracy: 0.8719 - val_loss: 0.4662 - val_accuracy: 0.8875\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.8719 - val_loss: 0.4606 - val_accuracy: 0.9000\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4695 - accuracy: 0.8719 - val_loss: 0.4550 - val_accuracy: 0.9125\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4642 - accuracy: 0.8750 - val_loss: 0.4494 - val_accuracy: 0.9125\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4589 - accuracy: 0.8781 - val_loss: 0.4438 - val_accuracy: 0.9125\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.8813 - val_loss: 0.4381 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a717b51f10>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_Threshold = MyThresholdCallBack(cl=0.92)\n",
    "\n",
    "seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[accuracy_Threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d664f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45069199800491333, 0.887499988079071]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7863d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4381323754787445, 0.925000011920929]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e804892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seq_model.predict(features) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e959accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[243,  14],\n",
       "       [ 28, 115]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, (seq_model.predict(features) > 0.5).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a72da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       257\n",
      "           1       0.89      0.80      0.85       143\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.89      0.87      0.88       400\n",
      "weighted avg       0.89      0.90      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, (seq_model.predict(features) > 0.5).astype('int32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7188165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter age of Customer: 19\n",
      "Enter salary of Customer: 76000\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "The Customer wih 19.0 and salary 76000.0 is going to purchare?: No\n"
     ]
    }
   ],
   "source": [
    "# Deployment with Input Example:\n",
    "\n",
    "# 1. Getting user input in the form of float\n",
    "ageInYears = float(input(\"Enter age of Customer: \"))\n",
    "salaryCust = float(input(\"Enter salary of Customer: \"))\n",
    "\n",
    "# 2. Converting input to 2d array since the same format was used for training this model\n",
    "custArray = np.array([[ageInYears, salaryCust]])\n",
    "\n",
    "# 3. Apply Standardization scince the same was done during the training of model\n",
    "scaledCustData = rbFeatures.transform(custArray)\n",
    "\n",
    "# 4. Predicting the salary\n",
    "#purchase = seq_model.predict(scaledCustData)\n",
    "\n",
    "# 5. Inverse Transform Label\n",
    "actualPurch = ((seq_model.predict(scaledCustData) > 0.5).astype('int32')).item()\n",
    "\n",
    "def final_rep(x):\n",
    "    if actualPurch == 0:\n",
    "        return \"No\"\n",
    "    if actualPurch == 1:\n",
    "        return \"Yes\"\n",
    "\n",
    "print(f\"The Customer wih {ageInYears} and salary {salaryCust} is going to purchare?: {final_rep(actualPurch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4dc655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.10769231,  0.13333333]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledCustData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303f8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
