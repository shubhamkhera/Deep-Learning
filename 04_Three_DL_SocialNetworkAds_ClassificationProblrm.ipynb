{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d26c67",
   "metadata": {},
   "source": [
    "# Day 3: 3.2\n",
    "\n",
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "## Here we are creating an DeepLearning model that can predict wether the customer is a good/bad on the basis of age and salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e820219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c69da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"03_Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79233b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2b4597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c4974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            0\n",
       "Gender             0\n",
       "Age                0\n",
       "EstimatedSalary    0\n",
       "Purchased          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b2e23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c789e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f12c22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules of Classification for ML:\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 1d NP array\n",
    "# 6. Normalization of features is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea641df",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c650cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6870a0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef8e1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Check the quality of model\n",
    "# 1. CHeck whether the model is a generalized or not\n",
    "print(log_model.score(X_train,y_train))\n",
    "print(log_model.score(X_test,y_test))\n",
    "\n",
    "# 2. CHeck the quality of model with respect to CL\n",
    "# SL = 0.1\n",
    "# CL = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e8a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for Deep Learning\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 2d NP array\n",
    "# 6. Features must be NORMALIZED\n",
    "# 7. For Binary Classification, label must be represented as 0 / 1 (pd.replace)\n",
    "# 8. For Multi-class classification, label must be  DISCRETE NUMERICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b6c53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,[4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "844e5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rbFeatures=RobustScaler()\n",
    "features = rbFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a613aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10d49961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "# Step1 : Architect the model\n",
    "# step 1.1: Create a Sequential Model\n",
    "\n",
    "seq_model = tf.keras.Sequential()\n",
    "\n",
    "# Step 1.2: Create Dense Layer\n",
    "# units = No. of neurons in Hidden Layer\n",
    "# activation = Which Activation Function to Apply\n",
    "# input_shape = Number of colums in FeatureArray\n",
    "\n",
    "\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1), input_shape = (2,)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e67b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "# Step2: Compile the mode:\n",
    "\n",
    "seq_model.compile(optimizer=\"sgd\", loss='binary_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c604fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4fe5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,cl):\n",
    "        super(MyThresholdCallBack, self).__init__()\n",
    "        self.cl = cl\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_score = logs[\"val_accuracy\"]\n",
    "        train_score = logs[\"accuracy\"]\n",
    "        \n",
    "        if test_score > train_score and test_score > self.cl:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa474aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 37ms/step - loss: 0.6688 - accuracy: 0.7969 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6624 - accuracy: 0.8000 - val_loss: 0.6535 - val_accuracy: 0.8250\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6564 - accuracy: 0.8062 - val_loss: 0.6471 - val_accuracy: 0.8500\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6506 - accuracy: 0.8000 - val_loss: 0.6407 - val_accuracy: 0.8625\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6447 - accuracy: 0.8000 - val_loss: 0.6343 - val_accuracy: 0.8500\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6389 - accuracy: 0.7969 - val_loss: 0.6279 - val_accuracy: 0.8500\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6332 - accuracy: 0.7844 - val_loss: 0.6217 - val_accuracy: 0.8500\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6275 - accuracy: 0.7812 - val_loss: 0.6155 - val_accuracy: 0.8250\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6218 - accuracy: 0.7781 - val_loss: 0.6093 - val_accuracy: 0.8125\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6160 - accuracy: 0.7750 - val_loss: 0.6030 - val_accuracy: 0.8125\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6101 - accuracy: 0.7750 - val_loss: 0.5968 - val_accuracy: 0.8125\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6043 - accuracy: 0.7781 - val_loss: 0.5907 - val_accuracy: 0.8125\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5984 - accuracy: 0.7750 - val_loss: 0.5846 - val_accuracy: 0.8125\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5928 - accuracy: 0.7750 - val_loss: 0.5786 - val_accuracy: 0.8125\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5872 - accuracy: 0.7750 - val_loss: 0.5726 - val_accuracy: 0.8000\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5816 - accuracy: 0.7750 - val_loss: 0.5667 - val_accuracy: 0.8000\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5763 - accuracy: 0.7750 - val_loss: 0.5608 - val_accuracy: 0.8000\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5707 - accuracy: 0.7781 - val_loss: 0.5549 - val_accuracy: 0.8000\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5653 - accuracy: 0.7781 - val_loss: 0.5491 - val_accuracy: 0.8125\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5599 - accuracy: 0.7781 - val_loss: 0.5432 - val_accuracy: 0.8125\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5547 - accuracy: 0.7844 - val_loss: 0.5374 - val_accuracy: 0.8125\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5493 - accuracy: 0.7844 - val_loss: 0.5315 - val_accuracy: 0.8125\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5440 - accuracy: 0.7875 - val_loss: 0.5257 - val_accuracy: 0.8125\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5387 - accuracy: 0.7875 - val_loss: 0.5199 - val_accuracy: 0.8125\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5335 - accuracy: 0.7906 - val_loss: 0.5141 - val_accuracy: 0.8125\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5282 - accuracy: 0.7906 - val_loss: 0.5083 - val_accuracy: 0.8125\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5229 - accuracy: 0.7906 - val_loss: 0.5025 - val_accuracy: 0.8125\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5176 - accuracy: 0.7906 - val_loss: 0.4966 - val_accuracy: 0.8250\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5124 - accuracy: 0.7906 - val_loss: 0.4908 - val_accuracy: 0.8250\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5071 - accuracy: 0.7906 - val_loss: 0.4848 - val_accuracy: 0.8250\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5019 - accuracy: 0.7906 - val_loss: 0.4788 - val_accuracy: 0.8250\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4966 - accuracy: 0.7906 - val_loss: 0.4728 - val_accuracy: 0.8250\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4913 - accuracy: 0.7937 - val_loss: 0.4668 - val_accuracy: 0.8250\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4862 - accuracy: 0.7937 - val_loss: 0.4609 - val_accuracy: 0.8250\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4810 - accuracy: 0.7906 - val_loss: 0.4550 - val_accuracy: 0.8375\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4759 - accuracy: 0.7906 - val_loss: 0.4492 - val_accuracy: 0.8375\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4709 - accuracy: 0.7937 - val_loss: 0.4434 - val_accuracy: 0.8375\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.7969 - val_loss: 0.4375 - val_accuracy: 0.8375\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.7969 - val_loss: 0.4319 - val_accuracy: 0.8375\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4561 - accuracy: 0.8031 - val_loss: 0.4262 - val_accuracy: 0.8500\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4511 - accuracy: 0.8094 - val_loss: 0.4207 - val_accuracy: 0.8375\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4465 - accuracy: 0.8062 - val_loss: 0.4153 - val_accuracy: 0.8375\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4420 - accuracy: 0.8062 - val_loss: 0.4100 - val_accuracy: 0.8375\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4374 - accuracy: 0.8062 - val_loss: 0.4048 - val_accuracy: 0.8375\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.8062 - val_loss: 0.3998 - val_accuracy: 0.8375\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4290 - accuracy: 0.8094 - val_loss: 0.3948 - val_accuracy: 0.8375\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.8062 - val_loss: 0.3900 - val_accuracy: 0.8500\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4208 - accuracy: 0.8062 - val_loss: 0.3852 - val_accuracy: 0.8500\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4169 - accuracy: 0.8094 - val_loss: 0.3805 - val_accuracy: 0.8500\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.8062 - val_loss: 0.3760 - val_accuracy: 0.8500\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4094 - accuracy: 0.8062 - val_loss: 0.3716 - val_accuracy: 0.8500\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4057 - accuracy: 0.8094 - val_loss: 0.3673 - val_accuracy: 0.8500\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4021 - accuracy: 0.8094 - val_loss: 0.3630 - val_accuracy: 0.8500\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3987 - accuracy: 0.8156 - val_loss: 0.3589 - val_accuracy: 0.8500\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3953 - accuracy: 0.8156 - val_loss: 0.3548 - val_accuracy: 0.8500\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3920 - accuracy: 0.8188 - val_loss: 0.3508 - val_accuracy: 0.8500\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3889 - accuracy: 0.8156 - val_loss: 0.3470 - val_accuracy: 0.8625\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8219 - val_loss: 0.3432 - val_accuracy: 0.8750\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3830 - accuracy: 0.8188 - val_loss: 0.3396 - val_accuracy: 0.8750\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3801 - accuracy: 0.8219 - val_loss: 0.3360 - val_accuracy: 0.8750\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3773 - accuracy: 0.8219 - val_loss: 0.3325 - val_accuracy: 0.8750\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3747 - accuracy: 0.8219 - val_loss: 0.3291 - val_accuracy: 0.8750\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3720 - accuracy: 0.8281 - val_loss: 0.3258 - val_accuracy: 0.8750\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8281 - val_loss: 0.3227 - val_accuracy: 0.8875\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3669 - accuracy: 0.8313 - val_loss: 0.3197 - val_accuracy: 0.8875\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8313 - val_loss: 0.3168 - val_accuracy: 0.8875\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3623 - accuracy: 0.8250 - val_loss: 0.3140 - val_accuracy: 0.8875\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3604 - accuracy: 0.8219 - val_loss: 0.3113 - val_accuracy: 0.8875\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3581 - accuracy: 0.8250 - val_loss: 0.3089 - val_accuracy: 0.8875\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8219 - val_loss: 0.3063 - val_accuracy: 0.8875\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3536 - accuracy: 0.8250 - val_loss: 0.3038 - val_accuracy: 0.8875\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3517 - accuracy: 0.8250 - val_loss: 0.3014 - val_accuracy: 0.8875\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3499 - accuracy: 0.8281 - val_loss: 0.2990 - val_accuracy: 0.8875\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8281 - val_loss: 0.2967 - val_accuracy: 0.8875\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3462 - accuracy: 0.8313 - val_loss: 0.2944 - val_accuracy: 0.8875\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3447 - accuracy: 0.8406 - val_loss: 0.2922 - val_accuracy: 0.9000\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8375 - val_loss: 0.2899 - val_accuracy: 0.9000\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3413 - accuracy: 0.8344 - val_loss: 0.2880 - val_accuracy: 0.8875\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3397 - accuracy: 0.8375 - val_loss: 0.2862 - val_accuracy: 0.8875\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3383 - accuracy: 0.8406 - val_loss: 0.2843 - val_accuracy: 0.8875\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3369 - accuracy: 0.8438 - val_loss: 0.2825 - val_accuracy: 0.8875\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3354 - accuracy: 0.8406 - val_loss: 0.2808 - val_accuracy: 0.8875\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.8500 - val_loss: 0.2790 - val_accuracy: 0.9000\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3326 - accuracy: 0.8500 - val_loss: 0.2773 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3315 - accuracy: 0.8469 - val_loss: 0.2758 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.8500 - val_loss: 0.2742 - val_accuracy: 0.9000\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3289 - accuracy: 0.8531 - val_loss: 0.2727 - val_accuracy: 0.9000\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.8562 - val_loss: 0.2713 - val_accuracy: 0.9000\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3268 - accuracy: 0.8562 - val_loss: 0.2698 - val_accuracy: 0.9000\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.8594 - val_loss: 0.2683 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3247 - accuracy: 0.8562 - val_loss: 0.2672 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3234 - accuracy: 0.8562 - val_loss: 0.2659 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3225 - accuracy: 0.8562 - val_loss: 0.2646 - val_accuracy: 0.9000\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3216 - accuracy: 0.8594 - val_loss: 0.2634 - val_accuracy: 0.9000\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3210 - accuracy: 0.8594 - val_loss: 0.2620 - val_accuracy: 0.9000\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3200 - accuracy: 0.8594 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3190 - accuracy: 0.8594 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3186 - accuracy: 0.8594 - val_loss: 0.2585 - val_accuracy: 0.9000\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3174 - accuracy: 0.8594 - val_loss: 0.2575 - val_accuracy: 0.9125\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8594 - val_loss: 0.2564 - val_accuracy: 0.9125\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8594 - val_loss: 0.2555 - val_accuracy: 0.9125\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3153 - accuracy: 0.8625 - val_loss: 0.2542 - val_accuracy: 0.9125\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3145 - accuracy: 0.8625 - val_loss: 0.2533 - val_accuracy: 0.9125\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3139 - accuracy: 0.8594 - val_loss: 0.2523 - val_accuracy: 0.9125\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3133 - accuracy: 0.8625 - val_loss: 0.2514 - val_accuracy: 0.9125\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3126 - accuracy: 0.8625 - val_loss: 0.2505 - val_accuracy: 0.9125\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3123 - accuracy: 0.8594 - val_loss: 0.2499 - val_accuracy: 0.9125\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3120 - accuracy: 0.8594 - val_loss: 0.2491 - val_accuracy: 0.9125\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3109 - accuracy: 0.8656 - val_loss: 0.2482 - val_accuracy: 0.9125\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3105 - accuracy: 0.8656 - val_loss: 0.2475 - val_accuracy: 0.9125\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3105 - accuracy: 0.8687 - val_loss: 0.2462 - val_accuracy: 0.9125\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3096 - accuracy: 0.8656 - val_loss: 0.2455 - val_accuracy: 0.9125\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3088 - accuracy: 0.8656 - val_loss: 0.2447 - val_accuracy: 0.9125\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3085 - accuracy: 0.8687 - val_loss: 0.2439 - val_accuracy: 0.9125\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.8687 - val_loss: 0.2431 - val_accuracy: 0.9125\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3074 - accuracy: 0.8687 - val_loss: 0.2424 - val_accuracy: 0.9125\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3071 - accuracy: 0.8687 - val_loss: 0.2418 - val_accuracy: 0.9125\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3063 - accuracy: 0.8687 - val_loss: 0.2411 - val_accuracy: 0.9125\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3059 - accuracy: 0.8687 - val_loss: 0.2404 - val_accuracy: 0.9125\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3055 - accuracy: 0.8687 - val_loss: 0.2397 - val_accuracy: 0.9125\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3053 - accuracy: 0.8750 - val_loss: 0.2389 - val_accuracy: 0.9125\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3048 - accuracy: 0.8719 - val_loss: 0.2382 - val_accuracy: 0.9125\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.8750 - val_loss: 0.2379 - val_accuracy: 0.9125\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3039 - accuracy: 0.8687 - val_loss: 0.2374 - val_accuracy: 0.9125\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3036 - accuracy: 0.8719 - val_loss: 0.2366 - val_accuracy: 0.9125\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3029 - accuracy: 0.8719 - val_loss: 0.2361 - val_accuracy: 0.9125\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3027 - accuracy: 0.8719 - val_loss: 0.2354 - val_accuracy: 0.9125\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8719 - val_loss: 0.2350 - val_accuracy: 0.9125\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.8781 - val_loss: 0.2345 - val_accuracy: 0.9125\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3013 - accuracy: 0.8781 - val_loss: 0.2341 - val_accuracy: 0.9125\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.3011 - accuracy: 0.8750 - val_loss: 0.2333 - val_accuracy: 0.9125\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3005 - accuracy: 0.8781 - val_loss: 0.2324 - val_accuracy: 0.9125\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3004 - accuracy: 0.8813 - val_loss: 0.2319 - val_accuracy: 0.9125\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3000 - accuracy: 0.8813 - val_loss: 0.2312 - val_accuracy: 0.9125\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2995 - accuracy: 0.8781 - val_loss: 0.2307 - val_accuracy: 0.9125\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.2992 - accuracy: 0.8781 - val_loss: 0.2299 - val_accuracy: 0.9125\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2986 - accuracy: 0.8813 - val_loss: 0.2293 - val_accuracy: 0.9125\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.2984 - accuracy: 0.8844 - val_loss: 0.2290 - val_accuracy: 0.9125\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2978 - accuracy: 0.8813 - val_loss: 0.2290 - val_accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f5ac958ca0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_Threshold = MyThresholdCallBack(cl=0.92)\n",
    "\n",
    "seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[accuracy_Threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d664f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29721641540527344, 0.8843749761581421]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7863d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2290 - accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22897687554359436, 0.925000011920929]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e804892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seq_model.predict(features) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e959accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[233,  24],\n",
       "       [ 19, 124]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, (seq_model.predict(features) > 0.5).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4a72da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       257\n",
      "           1       0.84      0.87      0.85       143\n",
      "\n",
      "    accuracy                           0.89       400\n",
      "   macro avg       0.88      0.89      0.88       400\n",
      "weighted avg       0.89      0.89      0.89       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, (seq_model.predict(features) > 0.5).astype('int32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7188165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter age of Customer: 50\n",
      "Enter salary of Customer: 20000\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "The Customer wih 50.0 and salary 20000.0 is going to purchare?: Yes\n"
     ]
    }
   ],
   "source": [
    "# Deployment with Input Example:\n",
    "\n",
    "# 1. Getting user input in the form of float\n",
    "ageInYears = float(input(\"Enter age of Customer: \"))\n",
    "salaryCust = float(input(\"Enter salary of Customer: \"))\n",
    "\n",
    "# 2. Converting input to 2d array since the same format was used for training this model\n",
    "custArray = np.array([[ageInYears, salaryCust]])\n",
    "\n",
    "# 3. Apply Standardization scince the same was done during the training of model\n",
    "scaledCustData = rbFeatures.transform(custArray)\n",
    "\n",
    "# 4. Predicting the salary\n",
    "#purchase = seq_model.predict(scaledCustData)\n",
    "\n",
    "# 5. Inverse Transform Label\n",
    "actualPurch = ((seq_model.predict(scaledCustData) > 0.5).astype('int32')).item()\n",
    "\n",
    "def final_rep(x):\n",
    "    if actualPurch == 0:\n",
    "        return \"No\"\n",
    "    if actualPurch == 1:\n",
    "        return \"Yes\"\n",
    "\n",
    "print(f\"The Customer wih {ageInYears} and salary {salaryCust} is going to purchare?: {final_rep(actualPurch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dc655e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
