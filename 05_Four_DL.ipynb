{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3740fd10",
   "metadata": {},
   "source": [
    "# Day 4: 4.1\n",
    "1. How to Deal with Multi-Class Classification\n",
    "2. Additional package which helps us Extended Matrix\n",
    "3. Cross Validation and Hyper parameter Tuning\n",
    "\n",
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "### Multi-class Classification:\n",
    "\n",
    "   - **Dealing with a dataset with categorical label column having more than 2 unique values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc157682",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25062b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f3ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/639388c2cbc2120a14dcf466e85730eb8be498bb/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edbcc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28ebdff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019d5e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a06689e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbcfad6",
   "metadata": {},
   "source": [
    "#### Here we can observe that the dataset is well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50e95227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "features = data.iloc[:,:-1].values\n",
    "label = data.iloc[:,[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4932e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scFeatures = StandardScaler()\n",
    "features = scFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bce8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle Multi-class classification by converting it ti an DummyVariable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "leSpecies = LabelEncoder()\n",
    "label = leSpecies.fit_transform(label)\n",
    "\n",
    "\n",
    "#label_2d = np.array(pd.get_dummies(label))\n",
    "\n",
    "# To create Dummy Variables we can use Keras Functionality\n",
    "kerasLabel = tf.keras.utils.to_categorical(label)\n",
    "kerasLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e44dbb",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "\n",
    "### 1. Architect the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f68c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step:1 Create a Sequential Model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Step2: Create Dense Layes with usints, activation and input shape\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu', input_shape=(4,)))  # Input Layer\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 1\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 2\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 3\n",
    "\n",
    "# Number of units in output layer for multi-class classification is equal to the no. of unique labels \n",
    "model.add(tf.keras.layers.Dense(units= 3, activation= 'softmax'))  # Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d2d428",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "\n",
    "\n",
    "- **Loss:** \n",
    "    - **binary_crossentropy (BinaryClassification)**\n",
    "    - **categorical_crossentropy (MuliclassClassification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd8bc6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e2173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "\n",
    "class MyThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,cl):\n",
    "        super(MyThresholdCallBack, self).__init__()\n",
    "        self.cl = cl\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_score = logs[\"val_accuracy\"]\n",
    "        train_score = logs[\"accuracy\"]\n",
    "        \n",
    "        if test_score > self.cl and test_score > train_score:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a94514",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbcc87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    kerasLabel, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16deb46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 83ms/step - loss: 1.2334 - accuracy: 0.3583 - val_loss: 1.2498 - val_accuracy: 0.2333\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1982 - accuracy: 0.3583 - val_loss: 1.2182 - val_accuracy: 0.2333\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1690 - accuracy: 0.3583 - val_loss: 1.1920 - val_accuracy: 0.2333\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.1442 - accuracy: 0.3583 - val_loss: 1.1695 - val_accuracy: 0.2333\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1216 - accuracy: 0.3583 - val_loss: 1.1495 - val_accuracy: 0.2333\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1026 - accuracy: 0.3583 - val_loss: 1.1318 - val_accuracy: 0.2333\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.0865 - accuracy: 0.3667 - val_loss: 1.1167 - val_accuracy: 0.2333\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0718 - accuracy: 0.3667 - val_loss: 1.1036 - val_accuracy: 0.2333\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0591 - accuracy: 0.3750 - val_loss: 1.0915 - val_accuracy: 0.2667\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0473 - accuracy: 0.3750 - val_loss: 1.0805 - val_accuracy: 0.2667\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0360 - accuracy: 0.3750 - val_loss: 1.0705 - val_accuracy: 0.2667\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0255 - accuracy: 0.3750 - val_loss: 1.0607 - val_accuracy: 0.2667\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0154 - accuracy: 0.3750 - val_loss: 1.0515 - val_accuracy: 0.2667\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.0056 - accuracy: 0.3833 - val_loss: 1.0428 - val_accuracy: 0.2667\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.9961 - accuracy: 0.3833 - val_loss: 1.0347 - val_accuracy: 0.2667\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9871 - accuracy: 0.3917 - val_loss: 1.0273 - val_accuracy: 0.2667\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9782 - accuracy: 0.3833 - val_loss: 1.0207 - val_accuracy: 0.3000\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.9697 - accuracy: 0.3917 - val_loss: 1.0140 - val_accuracy: 0.3000\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.9615 - accuracy: 0.4000 - val_loss: 1.0074 - val_accuracy: 0.3667\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.9535 - accuracy: 0.4667 - val_loss: 1.0005 - val_accuracy: 0.3667\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9451 - accuracy: 0.5167 - val_loss: 0.9937 - val_accuracy: 0.5667\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9365 - accuracy: 0.5917 - val_loss: 0.9868 - val_accuracy: 0.5667\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.9280 - accuracy: 0.6750 - val_loss: 0.9797 - val_accuracy: 0.6333\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9195 - accuracy: 0.7000 - val_loss: 0.9730 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9109 - accuracy: 0.7333 - val_loss: 0.9665 - val_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9026 - accuracy: 0.7500 - val_loss: 0.9599 - val_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8950 - accuracy: 0.7917 - val_loss: 0.9539 - val_accuracy: 0.7000\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.8875 - accuracy: 0.8083 - val_loss: 0.9477 - val_accuracy: 0.7000\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8797 - accuracy: 0.8167 - val_loss: 0.9418 - val_accuracy: 0.7000\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8724 - accuracy: 0.8250 - val_loss: 0.9358 - val_accuracy: 0.7000\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8655 - accuracy: 0.8333 - val_loss: 0.9298 - val_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8584 - accuracy: 0.8333 - val_loss: 0.9242 - val_accuracy: 0.7333\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8516 - accuracy: 0.8333 - val_loss: 0.9184 - val_accuracy: 0.7667\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.8451 - accuracy: 0.8333 - val_loss: 0.9129 - val_accuracy: 0.7667\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8388 - accuracy: 0.8333 - val_loss: 0.9070 - val_accuracy: 0.8000\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8324 - accuracy: 0.8333 - val_loss: 0.9013 - val_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.8259 - accuracy: 0.8333 - val_loss: 0.8954 - val_accuracy: 0.8333\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.8196 - accuracy: 0.8250 - val_loss: 0.8896 - val_accuracy: 0.8333\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8135 - accuracy: 0.8250 - val_loss: 0.8834 - val_accuracy: 0.8333\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8076 - accuracy: 0.8250 - val_loss: 0.8779 - val_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8016 - accuracy: 0.8250 - val_loss: 0.8721 - val_accuracy: 0.8667\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7956 - accuracy: 0.8250 - val_loss: 0.8666 - val_accuracy: 0.8667\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7896 - accuracy: 0.8250 - val_loss: 0.8609 - val_accuracy: 0.8667\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7843 - accuracy: 0.8333 - val_loss: 0.8556 - val_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.7780 - accuracy: 0.8250 - val_loss: 0.8497 - val_accuracy: 0.8667\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7719 - accuracy: 0.8333 - val_loss: 0.8438 - val_accuracy: 0.8667\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.7661 - accuracy: 0.8333 - val_loss: 0.8373 - val_accuracy: 0.8667\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7600 - accuracy: 0.8333 - val_loss: 0.8315 - val_accuracy: 0.8667\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.7540 - accuracy: 0.8333 - val_loss: 0.8255 - val_accuracy: 0.8667\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7478 - accuracy: 0.8333 - val_loss: 0.8198 - val_accuracy: 0.8667\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7429 - accuracy: 0.8333 - val_loss: 0.8134 - val_accuracy: 0.8667\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7355 - accuracy: 0.8333 - val_loss: 0.8068 - val_accuracy: 0.8667\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7294 - accuracy: 0.8250 - val_loss: 0.8004 - val_accuracy: 0.8667\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.7229 - accuracy: 0.8167 - val_loss: 0.7938 - val_accuracy: 0.8667\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7168 - accuracy: 0.8333 - val_loss: 0.7870 - val_accuracy: 0.8667\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7100 - accuracy: 0.8250 - val_loss: 0.7808 - val_accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7037 - accuracy: 0.8333 - val_loss: 0.7743 - val_accuracy: 0.8667\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.6969 - accuracy: 0.8250 - val_loss: 0.7678 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6912 - accuracy: 0.8250 - val_loss: 0.7612 - val_accuracy: 0.8667\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6837 - accuracy: 0.8250 - val_loss: 0.7543 - val_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6772 - accuracy: 0.8250 - val_loss: 0.7475 - val_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.6707 - accuracy: 0.8250 - val_loss: 0.7405 - val_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.6640 - accuracy: 0.8250 - val_loss: 0.7339 - val_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6568 - accuracy: 0.8250 - val_loss: 0.7269 - val_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6502 - accuracy: 0.8250 - val_loss: 0.7190 - val_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.6428 - accuracy: 0.8250 - val_loss: 0.7116 - val_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6357 - accuracy: 0.8250 - val_loss: 0.7045 - val_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6293 - accuracy: 0.8250 - val_loss: 0.6973 - val_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6218 - accuracy: 0.8250 - val_loss: 0.6898 - val_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6145 - accuracy: 0.8250 - val_loss: 0.6825 - val_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6068 - accuracy: 0.8250 - val_loss: 0.6743 - val_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5995 - accuracy: 0.8250 - val_loss: 0.6667 - val_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5921 - accuracy: 0.8250 - val_loss: 0.6582 - val_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5844 - accuracy: 0.8250 - val_loss: 0.6501 - val_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5769 - accuracy: 0.8333 - val_loss: 0.6423 - val_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5700 - accuracy: 0.8250 - val_loss: 0.6346 - val_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5621 - accuracy: 0.8250 - val_loss: 0.6262 - val_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5545 - accuracy: 0.8333 - val_loss: 0.6184 - val_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5470 - accuracy: 0.8333 - val_loss: 0.6111 - val_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5392 - accuracy: 0.8333 - val_loss: 0.6021 - val_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5315 - accuracy: 0.8333 - val_loss: 0.5935 - val_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5239 - accuracy: 0.8417 - val_loss: 0.5855 - val_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5174 - accuracy: 0.8417 - val_loss: 0.5781 - val_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5097 - accuracy: 0.8333 - val_loss: 0.5701 - val_accuracy: 0.9000\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5025 - accuracy: 0.8500 - val_loss: 0.5631 - val_accuracy: 0.9000\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4947 - accuracy: 0.8500 - val_loss: 0.5548 - val_accuracy: 0.9000\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4874 - accuracy: 0.8500 - val_loss: 0.5473 - val_accuracy: 0.9000\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4806 - accuracy: 0.8500 - val_loss: 0.5399 - val_accuracy: 0.9000\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4738 - accuracy: 0.8500 - val_loss: 0.5321 - val_accuracy: 0.9000\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4667 - accuracy: 0.8500 - val_loss: 0.5248 - val_accuracy: 0.9000\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4599 - accuracy: 0.8500 - val_loss: 0.5174 - val_accuracy: 0.9000\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4534 - accuracy: 0.8500 - val_loss: 0.5105 - val_accuracy: 0.9000\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4473 - accuracy: 0.8500 - val_loss: 0.5033 - val_accuracy: 0.9000\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4405 - accuracy: 0.8500 - val_loss: 0.4965 - val_accuracy: 0.9000\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4348 - accuracy: 0.8500 - val_loss: 0.4886 - val_accuracy: 0.9000\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.4288 - accuracy: 0.8583 - val_loss: 0.4811 - val_accuracy: 0.9000\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4233 - accuracy: 0.8667 - val_loss: 0.4754 - val_accuracy: 0.9000\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4169 - accuracy: 0.8833 - val_loss: 0.4694 - val_accuracy: 0.9000\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4112 - accuracy: 0.8833 - val_loss: 0.4630 - val_accuracy: 0.9000\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8917 - val_loss: 0.4573 - val_accuracy: 0.9000\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4008 - accuracy: 0.8917 - val_loss: 0.4516 - val_accuracy: 0.9000\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.3960 - accuracy: 0.8833 - val_loss: 0.4455 - val_accuracy: 0.9000\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3906 - accuracy: 0.8917 - val_loss: 0.4400 - val_accuracy: 0.9000\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3858 - accuracy: 0.8917 - val_loss: 0.4354 - val_accuracy: 0.9000\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3819 - accuracy: 0.8917 - val_loss: 0.4295 - val_accuracy: 0.9000\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3768 - accuracy: 0.8917 - val_loss: 0.4249 - val_accuracy: 0.9000\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3726 - accuracy: 0.8917 - val_loss: 0.4207 - val_accuracy: 0.9000\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3678 - accuracy: 0.8917 - val_loss: 0.4156 - val_accuracy: 0.9000\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3638 - accuracy: 0.8917 - val_loss: 0.4107 - val_accuracy: 0.9000\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3603 - accuracy: 0.8917 - val_loss: 0.4072 - val_accuracy: 0.9000\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3559 - accuracy: 0.8917 - val_loss: 0.4030 - val_accuracy: 0.9000\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3524 - accuracy: 0.8917 - val_loss: 0.3990 - val_accuracy: 0.9000\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3483 - accuracy: 0.8917 - val_loss: 0.3951 - val_accuracy: 0.9000\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3446 - accuracy: 0.8917 - val_loss: 0.3905 - val_accuracy: 0.9000\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3417 - accuracy: 0.8917 - val_loss: 0.3874 - val_accuracy: 0.9000\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3380 - accuracy: 0.8917 - val_loss: 0.3825 - val_accuracy: 0.9000\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3346 - accuracy: 0.9000 - val_loss: 0.3792 - val_accuracy: 0.9000\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3318 - accuracy: 0.9000 - val_loss: 0.3743 - val_accuracy: 0.9000\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.3282 - accuracy: 0.9000 - val_loss: 0.3707 - val_accuracy: 0.9000\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3256 - accuracy: 0.9083 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3219 - accuracy: 0.9000 - val_loss: 0.3648 - val_accuracy: 0.9000\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3194 - accuracy: 0.9083 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3174 - accuracy: 0.9167 - val_loss: 0.3583 - val_accuracy: 0.9000\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3151 - accuracy: 0.9083 - val_loss: 0.3547 - val_accuracy: 0.9000\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3112 - accuracy: 0.9250 - val_loss: 0.3528 - val_accuracy: 0.9000\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3080 - accuracy: 0.9083 - val_loss: 0.3491 - val_accuracy: 0.9000\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.3055 - accuracy: 0.9250 - val_loss: 0.3464 - val_accuracy: 0.9000\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3028 - accuracy: 0.9250 - val_loss: 0.3431 - val_accuracy: 0.9000\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3002 - accuracy: 0.9250 - val_loss: 0.3410 - val_accuracy: 0.9000\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2980 - accuracy: 0.9250 - val_loss: 0.3390 - val_accuracy: 0.9000\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.2951 - accuracy: 0.9250 - val_loss: 0.3361 - val_accuracy: 0.9000\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2930 - accuracy: 0.9250 - val_loss: 0.3340 - val_accuracy: 0.9000\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2912 - accuracy: 0.9167 - val_loss: 0.3287 - val_accuracy: 0.9000\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2878 - accuracy: 0.9333 - val_loss: 0.3264 - val_accuracy: 0.9000\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2855 - accuracy: 0.9333 - val_loss: 0.3241 - val_accuracy: 0.9000\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2832 - accuracy: 0.9333 - val_loss: 0.3217 - val_accuracy: 0.9000\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2811 - accuracy: 0.9333 - val_loss: 0.3204 - val_accuracy: 0.9000\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2794 - accuracy: 0.9333 - val_loss: 0.3183 - val_accuracy: 0.9000\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2769 - accuracy: 0.9333 - val_loss: 0.3152 - val_accuracy: 0.9000\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2745 - accuracy: 0.9333 - val_loss: 0.3134 - val_accuracy: 0.9000\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2729 - accuracy: 0.9333 - val_loss: 0.3113 - val_accuracy: 0.9000\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2705 - accuracy: 0.9333 - val_loss: 0.3092 - val_accuracy: 0.9000\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2686 - accuracy: 0.9333 - val_loss: 0.3050 - val_accuracy: 0.9000\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2662 - accuracy: 0.9333 - val_loss: 0.3030 - val_accuracy: 0.9000\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2654 - accuracy: 0.9333 - val_loss: 0.3029 - val_accuracy: 0.9000\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2627 - accuracy: 0.9333 - val_loss: 0.2988 - val_accuracy: 0.9000\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2612 - accuracy: 0.9333 - val_loss: 0.2973 - val_accuracy: 0.9000\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2591 - accuracy: 0.9417 - val_loss: 0.2966 - val_accuracy: 0.9000\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2573 - accuracy: 0.9417 - val_loss: 0.2944 - val_accuracy: 0.9000\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2547 - accuracy: 0.9333 - val_loss: 0.2920 - val_accuracy: 0.9000\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2534 - accuracy: 0.9417 - val_loss: 0.2888 - val_accuracy: 0.9000\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2515 - accuracy: 0.9417 - val_loss: 0.2858 - val_accuracy: 0.9000\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2494 - accuracy: 0.9417 - val_loss: 0.2832 - val_accuracy: 0.9000\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2476 - accuracy: 0.9417 - val_loss: 0.2826 - val_accuracy: 0.9000\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2459 - accuracy: 0.9417 - val_loss: 0.2815 - val_accuracy: 0.9000\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2444 - accuracy: 0.9417 - val_loss: 0.2788 - val_accuracy: 0.9000\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2424 - accuracy: 0.9417 - val_loss: 0.2783 - val_accuracy: 0.9000\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2412 - accuracy: 0.9417 - val_loss: 0.2764 - val_accuracy: 0.9000\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2395 - accuracy: 0.9500 - val_loss: 0.2753 - val_accuracy: 0.9000\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2375 - accuracy: 0.9417 - val_loss: 0.2727 - val_accuracy: 0.9000\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2358 - accuracy: 0.9500 - val_loss: 0.2719 - val_accuracy: 0.9000\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2340 - accuracy: 0.9500 - val_loss: 0.2703 - val_accuracy: 0.9000\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2326 - accuracy: 0.9417 - val_loss: 0.2687 - val_accuracy: 0.9000\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2313 - accuracy: 0.9417 - val_loss: 0.2651 - val_accuracy: 0.9000\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2298 - accuracy: 0.9500 - val_loss: 0.2632 - val_accuracy: 0.9000\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2279 - accuracy: 0.9500 - val_loss: 0.2618 - val_accuracy: 0.9000\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2265 - accuracy: 0.9500 - val_loss: 0.2607 - val_accuracy: 0.9000\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2251 - accuracy: 0.9500 - val_loss: 0.2600 - val_accuracy: 0.9000\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2233 - accuracy: 0.9500 - val_loss: 0.2579 - val_accuracy: 0.9000\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2222 - accuracy: 0.9583 - val_loss: 0.2559 - val_accuracy: 0.9000\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2209 - accuracy: 0.9583 - val_loss: 0.2542 - val_accuracy: 0.9000\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2201 - accuracy: 0.9500 - val_loss: 0.2515 - val_accuracy: 0.9000\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2183 - accuracy: 0.9500 - val_loss: 0.2510 - val_accuracy: 0.9000\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.2177 - accuracy: 0.9583 - val_loss: 0.2473 - val_accuracy: 0.9000\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.2153 - accuracy: 0.9500 - val_loss: 0.2461 - val_accuracy: 0.9000\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2139 - accuracy: 0.9500 - val_loss: 0.2454 - val_accuracy: 0.9000\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2121 - accuracy: 0.9583 - val_loss: 0.2452 - val_accuracy: 0.9000\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2107 - accuracy: 0.9583 - val_loss: 0.2442 - val_accuracy: 0.9000\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2095 - accuracy: 0.9583 - val_loss: 0.2427 - val_accuracy: 0.9000\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2098 - accuracy: 0.9583 - val_loss: 0.2397 - val_accuracy: 0.9000\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2073 - accuracy: 0.9583 - val_loss: 0.2376 - val_accuracy: 0.9000\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2064 - accuracy: 0.9583 - val_loss: 0.2385 - val_accuracy: 0.9000\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2042 - accuracy: 0.9583 - val_loss: 0.2376 - val_accuracy: 0.9000\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2031 - accuracy: 0.9583 - val_loss: 0.2356 - val_accuracy: 0.9000\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2019 - accuracy: 0.9583 - val_loss: 0.2342 - val_accuracy: 0.9000\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.2005 - accuracy: 0.9583 - val_loss: 0.2332 - val_accuracy: 0.9000\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1991 - accuracy: 0.9583 - val_loss: 0.2307 - val_accuracy: 0.9000\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1983 - accuracy: 0.9583 - val_loss: 0.2302 - val_accuracy: 0.9000\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1976 - accuracy: 0.9583 - val_loss: 0.2305 - val_accuracy: 0.9000\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1958 - accuracy: 0.9583 - val_loss: 0.2267 - val_accuracy: 0.9000\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1943 - accuracy: 0.9583 - val_loss: 0.2252 - val_accuracy: 0.9000\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1933 - accuracy: 0.9583 - val_loss: 0.2233 - val_accuracy: 0.9000\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1926 - accuracy: 0.9583 - val_loss: 0.2214 - val_accuracy: 0.9000\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1911 - accuracy: 0.9667 - val_loss: 0.2202 - val_accuracy: 0.9000\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1905 - accuracy: 0.9583 - val_loss: 0.2207 - val_accuracy: 0.9000\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1889 - accuracy: 0.9667 - val_loss: 0.2194 - val_accuracy: 0.9000\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1878 - accuracy: 0.9583 - val_loss: 0.2173 - val_accuracy: 0.9000\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1872 - accuracy: 0.9667 - val_loss: 0.2177 - val_accuracy: 0.9000\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1853 - accuracy: 0.9667 - val_loss: 0.2161 - val_accuracy: 0.9000\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1843 - accuracy: 0.9667 - val_loss: 0.2136 - val_accuracy: 0.9000\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1838 - accuracy: 0.9667 - val_loss: 0.2110 - val_accuracy: 0.9333\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1823 - accuracy: 0.9750 - val_loss: 0.2111 - val_accuracy: 0.9000\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1813 - accuracy: 0.9750 - val_loss: 0.2095 - val_accuracy: 0.9000\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1808 - accuracy: 0.9750 - val_loss: 0.2068 - val_accuracy: 0.9333\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1794 - accuracy: 0.9750 - val_loss: 0.2073 - val_accuracy: 0.9333\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1779 - accuracy: 0.9750 - val_loss: 0.2062 - val_accuracy: 0.9333\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1773 - accuracy: 0.9750 - val_loss: 0.2042 - val_accuracy: 0.9667\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1767 - accuracy: 0.9750 - val_loss: 0.2060 - val_accuracy: 0.9000\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1756 - accuracy: 0.9750 - val_loss: 0.2052 - val_accuracy: 0.9000\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1742 - accuracy: 0.9750 - val_loss: 0.2045 - val_accuracy: 0.9000\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1740 - accuracy: 0.9750 - val_loss: 0.2035 - val_accuracy: 0.9000\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1721 - accuracy: 0.9750 - val_loss: 0.2021 - val_accuracy: 0.9333\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1714 - accuracy: 0.9750 - val_loss: 0.1995 - val_accuracy: 0.9667\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1704 - accuracy: 0.9750 - val_loss: 0.1995 - val_accuracy: 0.9667\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1692 - accuracy: 0.9750 - val_loss: 0.1984 - val_accuracy: 0.9667\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1700 - accuracy: 0.9750 - val_loss: 0.1962 - val_accuracy: 0.9667\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1683 - accuracy: 0.9750 - val_loss: 0.1940 - val_accuracy: 0.9667\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1681 - accuracy: 0.9750 - val_loss: 0.1951 - val_accuracy: 0.9667\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1656 - accuracy: 0.9750 - val_loss: 0.1933 - val_accuracy: 0.9667\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1648 - accuracy: 0.9750 - val_loss: 0.1918 - val_accuracy: 0.9667\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.1638 - accuracy: 0.9750 - val_loss: 0.1911 - val_accuracy: 0.9667\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1637 - accuracy: 0.9750 - val_loss: 0.1924 - val_accuracy: 0.9667\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1637 - accuracy: 0.9750 - val_loss: 0.1911 - val_accuracy: 0.9667\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1616 - accuracy: 0.9750 - val_loss: 0.1901 - val_accuracy: 0.9667\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1607 - accuracy: 0.9750 - val_loss: 0.1893 - val_accuracy: 0.9667\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1602 - accuracy: 0.9750 - val_loss: 0.1872 - val_accuracy: 0.9667\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1587 - accuracy: 0.9750 - val_loss: 0.1852 - val_accuracy: 0.9667\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1588 - accuracy: 0.9750 - val_loss: 0.1849 - val_accuracy: 0.9667\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1572 - accuracy: 0.9750 - val_loss: 0.1834 - val_accuracy: 0.9667\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1564 - accuracy: 0.9750 - val_loss: 0.1831 - val_accuracy: 0.9667\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1558 - accuracy: 0.9750 - val_loss: 0.1813 - val_accuracy: 0.9667\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1546 - accuracy: 0.9750 - val_loss: 0.1800 - val_accuracy: 0.9667\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1544 - accuracy: 0.9750 - val_loss: 0.1789 - val_accuracy: 0.9667\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1541 - accuracy: 0.9750 - val_loss: 0.1787 - val_accuracy: 0.9667\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1529 - accuracy: 0.9750 - val_loss: 0.1779 - val_accuracy: 0.9667\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1515 - accuracy: 0.9750 - val_loss: 0.1760 - val_accuracy: 0.9667\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1517 - accuracy: 0.9750 - val_loss: 0.1733 - val_accuracy: 0.9667\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1502 - accuracy: 0.9750 - val_loss: 0.1730 - val_accuracy: 0.9667\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1495 - accuracy: 0.9750 - val_loss: 0.1715 - val_accuracy: 0.9667\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1496 - accuracy: 0.9750 - val_loss: 0.1734 - val_accuracy: 0.9667\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1479 - accuracy: 0.9750 - val_loss: 0.1718 - val_accuracy: 0.9667\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1481 - accuracy: 0.9750 - val_loss: 0.1718 - val_accuracy: 0.9667\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1471 - accuracy: 0.9750 - val_loss: 0.1701 - val_accuracy: 0.9667\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1465 - accuracy: 0.9750 - val_loss: 0.1706 - val_accuracy: 0.9667\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.1452 - accuracy: 0.9750 - val_loss: 0.1693 - val_accuracy: 0.9667\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1450 - accuracy: 0.9750 - val_loss: 0.1696 - val_accuracy: 0.9667\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1442 - accuracy: 0.9750 - val_loss: 0.1656 - val_accuracy: 0.9667\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1431 - accuracy: 0.9750 - val_loss: 0.1653 - val_accuracy: 0.9667\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.1426 - accuracy: 0.9750 - val_loss: 0.1627 - val_accuracy: 0.9667\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1422 - accuracy: 0.9750 - val_loss: 0.1625 - val_accuracy: 0.9667\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1412 - accuracy: 0.9750 - val_loss: 0.1606 - val_accuracy: 0.9667\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1410 - accuracy: 0.9750 - val_loss: 0.1596 - val_accuracy: 0.9667\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1406 - accuracy: 0.9750 - val_loss: 0.1593 - val_accuracy: 0.9667\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1390 - accuracy: 0.9750 - val_loss: 0.1581 - val_accuracy: 0.9667\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1398 - accuracy: 0.9750 - val_loss: 0.1603 - val_accuracy: 0.9667\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1381 - accuracy: 0.9750 - val_loss: 0.1599 - val_accuracy: 0.9667\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1371 - accuracy: 0.9750 - val_loss: 0.1574 - val_accuracy: 0.9667\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1379 - accuracy: 0.9750 - val_loss: 0.1538 - val_accuracy: 0.9667\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1362 - accuracy: 0.9750 - val_loss: 0.1535 - val_accuracy: 0.9667\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1352 - accuracy: 0.9750 - val_loss: 0.1529 - val_accuracy: 0.9667\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.1350 - accuracy: 0.9750 - val_loss: 0.1545 - val_accuracy: 0.9667\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1345 - accuracy: 0.9750 - val_loss: 0.1515 - val_accuracy: 0.9667\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1343 - accuracy: 0.9750 - val_loss: 0.1516 - val_accuracy: 0.9667\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1330 - accuracy: 0.9750 - val_loss: 0.1506 - val_accuracy: 0.9667\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1336 - accuracy: 0.9750 - val_loss: 0.1504 - val_accuracy: 0.9667\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1320 - accuracy: 0.9750 - val_loss: 0.1493 - val_accuracy: 0.9667\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1317 - accuracy: 0.9750 - val_loss: 0.1488 - val_accuracy: 0.9667\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1311 - accuracy: 0.9750 - val_loss: 0.1477 - val_accuracy: 0.9667\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1309 - accuracy: 0.9750 - val_loss: 0.1466 - val_accuracy: 0.9667\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1296 - accuracy: 0.9750 - val_loss: 0.1456 - val_accuracy: 0.9667\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1289 - accuracy: 0.9750 - val_loss: 0.1457 - val_accuracy: 0.9667\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1286 - accuracy: 0.9750 - val_loss: 0.1452 - val_accuracy: 0.9667\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1285 - accuracy: 0.9750 - val_loss: 0.1430 - val_accuracy: 0.9667\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1274 - accuracy: 0.9750 - val_loss: 0.1443 - val_accuracy: 0.9667\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.1268 - accuracy: 0.9750 - val_loss: 0.1439 - val_accuracy: 0.9667\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1268 - accuracy: 0.9750 - val_loss: 0.1445 - val_accuracy: 0.9667\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1261 - accuracy: 0.9750 - val_loss: 0.1436 - val_accuracy: 0.9667\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1263 - accuracy: 0.9667 - val_loss: 0.1392 - val_accuracy: 0.9667\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1245 - accuracy: 0.9750 - val_loss: 0.1394 - val_accuracy: 0.9667\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1239 - accuracy: 0.9750 - val_loss: 0.1388 - val_accuracy: 0.9667\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1236 - accuracy: 0.9750 - val_loss: 0.1390 - val_accuracy: 0.9667\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1236 - accuracy: 0.9750 - val_loss: 0.1385 - val_accuracy: 0.9667\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.1229 - accuracy: 0.9750 - val_loss: 0.1372 - val_accuracy: 0.9667\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1224 - accuracy: 0.9750 - val_loss: 0.1354 - val_accuracy: 0.9667\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1222 - accuracy: 0.9750 - val_loss: 0.1338 - val_accuracy: 0.9667\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1210 - accuracy: 0.9750 - val_loss: 0.1341 - val_accuracy: 0.9667\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.1351 - val_accuracy: 0.9667\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.1212 - accuracy: 0.9750 - val_loss: 0.1359 - val_accuracy: 0.9667\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1201 - accuracy: 0.9750 - val_loss: 0.1354 - val_accuracy: 0.9667\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1196 - accuracy: 0.9750 - val_loss: 0.1352 - val_accuracy: 0.9667\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1188 - accuracy: 0.9750 - val_loss: 0.1335 - val_accuracy: 0.9667\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1183 - accuracy: 0.9750 - val_loss: 0.1325 - val_accuracy: 0.9667\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1187 - accuracy: 0.9750 - val_loss: 0.1322 - val_accuracy: 0.9667\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1176 - accuracy: 0.9750 - val_loss: 0.1296 - val_accuracy: 0.9667\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1183 - accuracy: 0.9750 - val_loss: 0.1282 - val_accuracy: 0.9667\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1172 - accuracy: 0.9750 - val_loss: 0.1292 - val_accuracy: 0.9667\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1162 - accuracy: 0.9667 - val_loss: 0.1282 - val_accuracy: 0.9667\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1157 - accuracy: 0.9750 - val_loss: 0.1282 - val_accuracy: 0.9667\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1153 - accuracy: 0.9750 - val_loss: 0.1275 - val_accuracy: 0.9667\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1148 - accuracy: 0.9750 - val_loss: 0.1277 - val_accuracy: 0.9667\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.1258 - val_accuracy: 0.9667\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1148 - accuracy: 0.9750 - val_loss: 0.1257 - val_accuracy: 0.9667\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1139 - accuracy: 0.9750 - val_loss: 0.1256 - val_accuracy: 0.9667\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1140 - accuracy: 0.9750 - val_loss: 0.1252 - val_accuracy: 0.9667\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1151 - accuracy: 0.9667 - val_loss: 0.1233 - val_accuracy: 0.9667\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1126 - accuracy: 0.9667 - val_loss: 0.1211 - val_accuracy: 0.9667\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1128 - accuracy: 0.9667 - val_loss: 0.1206 - val_accuracy: 0.9667\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1115 - accuracy: 0.9750 - val_loss: 0.1204 - val_accuracy: 0.9667\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1113 - accuracy: 0.9750 - val_loss: 0.1212 - val_accuracy: 0.9667\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1108 - accuracy: 0.9667 - val_loss: 0.1193 - val_accuracy: 0.9667\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1103 - accuracy: 0.9750 - val_loss: 0.1190 - val_accuracy: 0.9667\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.1182 - val_accuracy: 0.9667\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1098 - accuracy: 0.9667 - val_loss: 0.1186 - val_accuracy: 0.9667\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1095 - accuracy: 0.9667 - val_loss: 0.1165 - val_accuracy: 0.9667\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1090 - accuracy: 0.9667 - val_loss: 0.1169 - val_accuracy: 0.9667\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1084 - accuracy: 0.9750 - val_loss: 0.1169 - val_accuracy: 0.9667\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1083 - accuracy: 0.9750 - val_loss: 0.1156 - val_accuracy: 0.9667\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1077 - accuracy: 0.9750 - val_loss: 0.1147 - val_accuracy: 0.9667\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.1072 - accuracy: 0.9750 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1073 - accuracy: 0.9667 - val_loss: 0.1138 - val_accuracy: 0.9667\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1063 - accuracy: 0.9667 - val_loss: 0.1129 - val_accuracy: 0.9667\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1065 - accuracy: 0.9667 - val_loss: 0.1121 - val_accuracy: 0.9667\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.1111 - val_accuracy: 0.9667\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1055 - accuracy: 0.9667 - val_loss: 0.1117 - val_accuracy: 0.9667\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1060 - accuracy: 0.9750 - val_loss: 0.1128 - val_accuracy: 0.9667\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1053 - accuracy: 0.9583 - val_loss: 0.1129 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "accuracy_Threshold = MyThresholdCallBack(cl=0.95)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[accuracy_Threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8446934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9667\n",
      "[0.10422959923744202, 0.9666666388511658]\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1129 - accuracy: 0.9667\n",
      "[0.1129152774810791, 0.9666666388511658]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f18491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 45,  5],\n",
       "       [ 0,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, np.argmax(model.predict(features), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5e4ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      0.90      0.95        50\n",
      "           2       0.91      1.00      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, (np.argmax(model.predict(features), axis=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1336c6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1adb58a4b50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.legend(['TestScore', 'TrainScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b6208f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_func():\n",
    "    # Inputs\n",
    "    sLength = float(input(\"Enter sepal length: \"))\n",
    "    sWidth = float(input(\"Enter sepal width: \"))\n",
    "    pLength = float(input(\"Enter petal length: \"))\n",
    "    pWidth = float(input(\"Enter petal width: \"))\n",
    "    \n",
    "    # Creating a 2d array from inputs\n",
    "    inpFeatures = np.array([[sLength,sWidth,pLength,pWidth]])\n",
    "    \n",
    "    # Transforming array as we have earlier perform the same\n",
    "    scaledInput = scFeatures.transform(inpFeatures)\n",
    "\n",
    "    # Predicting labeled value from scaled input\n",
    "    predSpecies = (np.argmax(model.predict(scaledInput), axis=-1))\n",
    "\n",
    "    # Fetching the type of flower\n",
    "    flowerType = leSpecies.inverse_transform(predSpecies).item()\n",
    "\n",
    "    print(f\"The Flower having \\n sepal_length: {sLength} \\n sepal_width: {sWidth} \\n petal_length: {pLength} \\n petal_width: {pWidth} \\n represents ==> {flowerType}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb19706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sepal length: 5.1\n",
      "Enter sepal width: 1.6\n",
      "Enter petal length: 3.1\n",
      "Enter petal width: 0.2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "The Flower having \n",
      " sepal_length: 5.1 \n",
      " sepal_width: 1.6 \n",
      " petal_length: 3.1 \n",
      " petal_width: 0.2 \n",
      " represents ==> versicolor\n"
     ]
    }
   ],
   "source": [
    "prediction_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33b374e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sepal length: 8\n",
      "Enter sepal width: 6\n",
      "Enter petal length: 1\n",
      "Enter petal width: 2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "The Flower having \n",
      " sepal_length: 8.0 \n",
      " sepal_width: 6.0 \n",
      " petal_length: 1.0 \n",
      " petal_width: 2.0 \n",
      " represents ==> setosa\n"
     ]
    }
   ],
   "source": [
    "prediction_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa19a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42611af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
