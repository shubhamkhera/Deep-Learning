{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760c2e53",
   "metadata": {},
   "source": [
    "# Day 4: 4.1\n",
    "1. How to Deal with Multi-Class Classification\n",
    "2. Additional package which helps us Extended Matrix\n",
    "3. Cross Validation and Hyper parameter Tuning\n",
    "\n",
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "### Multi-class Classification:\n",
    "\n",
    "   - **Dealing with a dataset with categorical label column having more than 2 unique values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727fcfd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db94de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62232f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/639388c2cbc2120a14dcf466e85730eb8be498bb/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c15ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fade1911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e42e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5ccdd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76a5d7",
   "metadata": {},
   "source": [
    "#### Here we can observe that the dataset is well balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca06c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features and labels\n",
    "features = data.iloc[:,:-1].values\n",
    "label = data.iloc[:,[-1]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f67b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scFeatures = StandardScaler()\n",
    "features = scFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b622c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle Multi-class classification by converting it ti an DummyVariable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "leSpecies = LabelEncoder()\n",
    "label = leSpecies.fit_transform(label)\n",
    "\n",
    "\n",
    "#label_2d = np.array(pd.get_dummies(label))\n",
    "\n",
    "# To create Dummy Variables we can use Keras Functionality\n",
    "kerasLabel = tf.keras.utils.to_categorical(label)\n",
    "kerasLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15030e7",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "\n",
    "### 1. Architect the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbde5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step:1 Create a Sequential Model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Step2: Create Dense Layes with usints, activation and input shape\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu', input_shape=(4,)))  # Input Layer\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 1\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 2\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 3\n",
    "\n",
    "# Number of units in output layer for multi-class classification is equal to the no. of unique labels \n",
    "model.add(tf.keras.layers.Dense(units= 3, activation= 'softmax'))  # Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c60384",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "\n",
    "\n",
    "- **Loss:** \n",
    "    - **binary_crossentropy (BinaryClassification)**\n",
    "    - **categorical_crossentropy (MuliclassClassification)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f7e2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c11a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Callback\n",
    "\n",
    "class MyThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,cl):\n",
    "        super(MyThresholdCallBack, self).__init__()\n",
    "        self.cl = cl\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_score = logs[\"val_accuracy\"]\n",
    "        train_score = logs[\"accuracy\"]\n",
    "        \n",
    "        if test_score > self.cl and test_score > train_score:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a50a61f",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006d20da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    kerasLabel, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea31cd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 1s 121ms/step - loss: 1.1289 - accuracy: 0.1917 - val_loss: 1.1314 - val_accuracy: 0.2333\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 1.1135 - accuracy: 0.2333 - val_loss: 1.1157 - val_accuracy: 0.2333\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0979 - accuracy: 0.3167 - val_loss: 1.1000 - val_accuracy: 0.2333\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0831 - accuracy: 0.3417 - val_loss: 1.0846 - val_accuracy: 0.2333\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0691 - accuracy: 0.3500 - val_loss: 1.0694 - val_accuracy: 0.2667\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.0547 - accuracy: 0.4333 - val_loss: 1.0554 - val_accuracy: 0.3333\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0410 - accuracy: 0.4833 - val_loss: 1.0419 - val_accuracy: 0.5000\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0279 - accuracy: 0.6417 - val_loss: 1.0291 - val_accuracy: 0.5667\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0161 - accuracy: 0.6667 - val_loss: 1.0172 - val_accuracy: 0.5667\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0048 - accuracy: 0.7500 - val_loss: 1.0048 - val_accuracy: 0.7000\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9935 - accuracy: 0.7750 - val_loss: 0.9930 - val_accuracy: 0.7000\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.9827 - accuracy: 0.7833 - val_loss: 0.9813 - val_accuracy: 0.7000\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.9716 - accuracy: 0.7667 - val_loss: 0.9697 - val_accuracy: 0.7000\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.9605 - accuracy: 0.7750 - val_loss: 0.9578 - val_accuracy: 0.7000\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.9491 - accuracy: 0.7750 - val_loss: 0.9459 - val_accuracy: 0.7667\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.9379 - accuracy: 0.7917 - val_loss: 0.9339 - val_accuracy: 0.7000\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9263 - accuracy: 0.7667 - val_loss: 0.9217 - val_accuracy: 0.7000\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9144 - accuracy: 0.7750 - val_loss: 0.9093 - val_accuracy: 0.7000\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9031 - accuracy: 0.7583 - val_loss: 0.8968 - val_accuracy: 0.7000\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8906 - accuracy: 0.7500 - val_loss: 0.8844 - val_accuracy: 0.7000\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8788 - accuracy: 0.7333 - val_loss: 0.8719 - val_accuracy: 0.7000\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8674 - accuracy: 0.7167 - val_loss: 0.8593 - val_accuracy: 0.6667\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.8549 - accuracy: 0.7333 - val_loss: 0.8464 - val_accuracy: 0.6667\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8428 - accuracy: 0.7333 - val_loss: 0.8341 - val_accuracy: 0.6667\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.8308 - accuracy: 0.7500 - val_loss: 0.8218 - val_accuracy: 0.6667\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8185 - accuracy: 0.7333 - val_loss: 0.8093 - val_accuracy: 0.7000\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8061 - accuracy: 0.7500 - val_loss: 0.7967 - val_accuracy: 0.7000\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7936 - accuracy: 0.7500 - val_loss: 0.7841 - val_accuracy: 0.7000\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7814 - accuracy: 0.7583 - val_loss: 0.7718 - val_accuracy: 0.7000\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7695 - accuracy: 0.7500 - val_loss: 0.7595 - val_accuracy: 0.7000\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7568 - accuracy: 0.7667 - val_loss: 0.7473 - val_accuracy: 0.7333\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7443 - accuracy: 0.7667 - val_loss: 0.7357 - val_accuracy: 0.7000\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7323 - accuracy: 0.7750 - val_loss: 0.7239 - val_accuracy: 0.6667\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7200 - accuracy: 0.7750 - val_loss: 0.7122 - val_accuracy: 0.6667\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7082 - accuracy: 0.7833 - val_loss: 0.7010 - val_accuracy: 0.7000\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6962 - accuracy: 0.7833 - val_loss: 0.6904 - val_accuracy: 0.7000\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.6847 - accuracy: 0.8083 - val_loss: 0.6801 - val_accuracy: 0.7000\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.6733 - accuracy: 0.8250 - val_loss: 0.6698 - val_accuracy: 0.7000\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6624 - accuracy: 0.8250 - val_loss: 0.6600 - val_accuracy: 0.7000\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.6519 - accuracy: 0.8250 - val_loss: 0.6507 - val_accuracy: 0.7000\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6417 - accuracy: 0.8417 - val_loss: 0.6417 - val_accuracy: 0.7000\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.6317 - accuracy: 0.8250 - val_loss: 0.6332 - val_accuracy: 0.7000\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.6226 - accuracy: 0.8500 - val_loss: 0.6254 - val_accuracy: 0.7333\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.6128 - accuracy: 0.8583 - val_loss: 0.6173 - val_accuracy: 0.7333\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.6039 - accuracy: 0.8583 - val_loss: 0.6094 - val_accuracy: 0.7333\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5953 - accuracy: 0.8583 - val_loss: 0.6025 - val_accuracy: 0.7667\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5868 - accuracy: 0.8667 - val_loss: 0.5958 - val_accuracy: 0.7667\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5790 - accuracy: 0.8750 - val_loss: 0.5893 - val_accuracy: 0.8000\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5711 - accuracy: 0.8750 - val_loss: 0.5835 - val_accuracy: 0.7667\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5638 - accuracy: 0.8833 - val_loss: 0.5777 - val_accuracy: 0.7667\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5565 - accuracy: 0.8917 - val_loss: 0.5721 - val_accuracy: 0.7667\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.5496 - accuracy: 0.8833 - val_loss: 0.5669 - val_accuracy: 0.7667\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5437 - accuracy: 0.8750 - val_loss: 0.5621 - val_accuracy: 0.7667\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5364 - accuracy: 0.8750 - val_loss: 0.5575 - val_accuracy: 0.7667\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5305 - accuracy: 0.8750 - val_loss: 0.5532 - val_accuracy: 0.7667\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5242 - accuracy: 0.8667 - val_loss: 0.5488 - val_accuracy: 0.7667\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.5179 - accuracy: 0.8667 - val_loss: 0.5449 - val_accuracy: 0.7667\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.5128 - accuracy: 0.8583 - val_loss: 0.5409 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.5083 - accuracy: 0.8583 - val_loss: 0.5372 - val_accuracy: 0.7667\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5017 - accuracy: 0.8667 - val_loss: 0.5332 - val_accuracy: 0.7667\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4963 - accuracy: 0.8667 - val_loss: 0.5301 - val_accuracy: 0.7667\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4913 - accuracy: 0.8500 - val_loss: 0.5261 - val_accuracy: 0.7667\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4864 - accuracy: 0.8500 - val_loss: 0.5228 - val_accuracy: 0.7667\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4814 - accuracy: 0.8417 - val_loss: 0.5195 - val_accuracy: 0.7667\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4770 - accuracy: 0.8583 - val_loss: 0.5172 - val_accuracy: 0.7333\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4720 - accuracy: 0.8250 - val_loss: 0.5139 - val_accuracy: 0.7333\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.4676 - accuracy: 0.8333 - val_loss: 0.5114 - val_accuracy: 0.7000\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4630 - accuracy: 0.8250 - val_loss: 0.5079 - val_accuracy: 0.7000\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4588 - accuracy: 0.8167 - val_loss: 0.5049 - val_accuracy: 0.7000\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4546 - accuracy: 0.8250 - val_loss: 0.5020 - val_accuracy: 0.7000\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4507 - accuracy: 0.8083 - val_loss: 0.4993 - val_accuracy: 0.7000\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4465 - accuracy: 0.8250 - val_loss: 0.4964 - val_accuracy: 0.7000\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4435 - accuracy: 0.8333 - val_loss: 0.4950 - val_accuracy: 0.7000\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4392 - accuracy: 0.8167 - val_loss: 0.4921 - val_accuracy: 0.7000\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4349 - accuracy: 0.8000 - val_loss: 0.4888 - val_accuracy: 0.7000\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4313 - accuracy: 0.8167 - val_loss: 0.4860 - val_accuracy: 0.7333\n",
      "Epoch 77/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4274 - accuracy: 0.8167 - val_loss: 0.4828 - val_accuracy: 0.7333\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4244 - accuracy: 0.8083 - val_loss: 0.4800 - val_accuracy: 0.7333\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4203 - accuracy: 0.8167 - val_loss: 0.4769 - val_accuracy: 0.7333\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4171 - accuracy: 0.8167 - val_loss: 0.4743 - val_accuracy: 0.7333\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4135 - accuracy: 0.8083 - val_loss: 0.4709 - val_accuracy: 0.7333\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4109 - accuracy: 0.8250 - val_loss: 0.4690 - val_accuracy: 0.7333\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4076 - accuracy: 0.8083 - val_loss: 0.4648 - val_accuracy: 0.7333\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.4036 - accuracy: 0.8333 - val_loss: 0.4613 - val_accuracy: 0.7333\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4002 - accuracy: 0.8417 - val_loss: 0.4581 - val_accuracy: 0.7333\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3972 - accuracy: 0.8583 - val_loss: 0.4551 - val_accuracy: 0.7333\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3945 - accuracy: 0.8667 - val_loss: 0.4531 - val_accuracy: 0.7333\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 0.3908 - accuracy: 0.8583 - val_loss: 0.4506 - val_accuracy: 0.7333\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3875 - accuracy: 0.8500 - val_loss: 0.4471 - val_accuracy: 0.7333\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3847 - accuracy: 0.8583 - val_loss: 0.4429 - val_accuracy: 0.7333\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3820 - accuracy: 0.8667 - val_loss: 0.4394 - val_accuracy: 0.7667\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3781 - accuracy: 0.8917 - val_loss: 0.4363 - val_accuracy: 0.7667\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3756 - accuracy: 0.8917 - val_loss: 0.4324 - val_accuracy: 0.7667\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3722 - accuracy: 0.9167 - val_loss: 0.4294 - val_accuracy: 0.7667\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3689 - accuracy: 0.9250 - val_loss: 0.4267 - val_accuracy: 0.7667\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3663 - accuracy: 0.9250 - val_loss: 0.4240 - val_accuracy: 0.8000\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3643 - accuracy: 0.9083 - val_loss: 0.4218 - val_accuracy: 0.8000\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3596 - accuracy: 0.9083 - val_loss: 0.4189 - val_accuracy: 0.8000\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3570 - accuracy: 0.9083 - val_loss: 0.4139 - val_accuracy: 0.8000\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3533 - accuracy: 0.9250 - val_loss: 0.4112 - val_accuracy: 0.8000\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3505 - accuracy: 0.9250 - val_loss: 0.4082 - val_accuracy: 0.8000\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 0s 34ms/step - loss: 0.3474 - accuracy: 0.9167 - val_loss: 0.4052 - val_accuracy: 0.8000\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3449 - accuracy: 0.9167 - val_loss: 0.4000 - val_accuracy: 0.8333\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3414 - accuracy: 0.9250 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3385 - accuracy: 0.9250 - val_loss: 0.3944 - val_accuracy: 0.8333\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3355 - accuracy: 0.9250 - val_loss: 0.3924 - val_accuracy: 0.8333\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3332 - accuracy: 0.9250 - val_loss: 0.3893 - val_accuracy: 0.8333\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3299 - accuracy: 0.9167 - val_loss: 0.3843 - val_accuracy: 0.8333\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3274 - accuracy: 0.9333 - val_loss: 0.3821 - val_accuracy: 0.8333\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3237 - accuracy: 0.9250 - val_loss: 0.3779 - val_accuracy: 0.8333\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3215 - accuracy: 0.9250 - val_loss: 0.3743 - val_accuracy: 0.8333\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3180 - accuracy: 0.9333 - val_loss: 0.3722 - val_accuracy: 0.8333\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3154 - accuracy: 0.9333 - val_loss: 0.3687 - val_accuracy: 0.8333\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3127 - accuracy: 0.9333 - val_loss: 0.3655 - val_accuracy: 0.8333\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3095 - accuracy: 0.9333 - val_loss: 0.3617 - val_accuracy: 0.8333\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3068 - accuracy: 0.9333 - val_loss: 0.3583 - val_accuracy: 0.8333\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3044 - accuracy: 0.9333 - val_loss: 0.3543 - val_accuracy: 0.8333\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3011 - accuracy: 0.9333 - val_loss: 0.3513 - val_accuracy: 0.8333\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2985 - accuracy: 0.9333 - val_loss: 0.3497 - val_accuracy: 0.8333\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2960 - accuracy: 0.9333 - val_loss: 0.3477 - val_accuracy: 0.8333\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.2944 - accuracy: 0.9333 - val_loss: 0.3442 - val_accuracy: 0.8333\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2910 - accuracy: 0.9333 - val_loss: 0.3413 - val_accuracy: 0.8333\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2884 - accuracy: 0.9417 - val_loss: 0.3395 - val_accuracy: 0.8333\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2851 - accuracy: 0.9333 - val_loss: 0.3352 - val_accuracy: 0.8333\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2827 - accuracy: 0.9333 - val_loss: 0.3307 - val_accuracy: 0.8333\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2800 - accuracy: 0.9417 - val_loss: 0.3280 - val_accuracy: 0.8667\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2780 - accuracy: 0.9500 - val_loss: 0.3274 - val_accuracy: 0.8333\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.2753 - accuracy: 0.9417 - val_loss: 0.3224 - val_accuracy: 0.8667\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2727 - accuracy: 0.9417 - val_loss: 0.3205 - val_accuracy: 0.8667\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2708 - accuracy: 0.9417 - val_loss: 0.3162 - val_accuracy: 0.8667\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2676 - accuracy: 0.9417 - val_loss: 0.3133 - val_accuracy: 0.8667\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2654 - accuracy: 0.9417 - val_loss: 0.3099 - val_accuracy: 0.8667\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2634 - accuracy: 0.9500 - val_loss: 0.3080 - val_accuracy: 0.8667\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2617 - accuracy: 0.9417 - val_loss: 0.3026 - val_accuracy: 0.9000\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2580 - accuracy: 0.9583 - val_loss: 0.3002 - val_accuracy: 0.9000\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2555 - accuracy: 0.9583 - val_loss: 0.2986 - val_accuracy: 0.9000\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2534 - accuracy: 0.9583 - val_loss: 0.2954 - val_accuracy: 0.9000\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2509 - accuracy: 0.9583 - val_loss: 0.2926 - val_accuracy: 0.9333\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2490 - accuracy: 0.9583 - val_loss: 0.2899 - val_accuracy: 0.9333\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2466 - accuracy: 0.9583 - val_loss: 0.2882 - val_accuracy: 0.9333\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2445 - accuracy: 0.9583 - val_loss: 0.2851 - val_accuracy: 0.9333\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2417 - accuracy: 0.9583 - val_loss: 0.2817 - val_accuracy: 0.9333\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2398 - accuracy: 0.9583 - val_loss: 0.2800 - val_accuracy: 0.9333\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2373 - accuracy: 0.9583 - val_loss: 0.2764 - val_accuracy: 0.9333\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2352 - accuracy: 0.9583 - val_loss: 0.2741 - val_accuracy: 0.9333\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2329 - accuracy: 0.9583 - val_loss: 0.2714 - val_accuracy: 0.9333\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2309 - accuracy: 0.9583 - val_loss: 0.2687 - val_accuracy: 0.9333\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2288 - accuracy: 0.9583 - val_loss: 0.2670 - val_accuracy: 0.9333\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.2268 - accuracy: 0.9583 - val_loss: 0.2654 - val_accuracy: 0.9333\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2246 - accuracy: 0.9583 - val_loss: 0.2621 - val_accuracy: 0.9333\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2226 - accuracy: 0.9583 - val_loss: 0.2597 - val_accuracy: 0.9333\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2205 - accuracy: 0.9583 - val_loss: 0.2567 - val_accuracy: 0.9333\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2193 - accuracy: 0.9583 - val_loss: 0.2527 - val_accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "accuracy_Threshold = MyThresholdCallBack(cl=0.95)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[accuracy_Threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b37493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2172 - accuracy: 0.9667\n",
      "[0.21715863049030304, 0.9666666388511658]\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2527 - accuracy: 0.9667\n",
      "[0.2527363896369934, 0.9666666388511658]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train))\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f2c4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  0,  0],\n",
       "       [ 0, 45,  5],\n",
       "       [ 0,  0, 50]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, np.argmax(model.predict(features), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b6c9491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      0.90      0.95        50\n",
      "           2       0.91      1.00      0.95        50\n",
      "\n",
      "    accuracy                           0.97       150\n",
      "   macro avg       0.97      0.97      0.97       150\n",
      "weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, (np.argmax(model.predict(features), axis=-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "535d19b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23763d20be0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "\n",
    "plt.legend(['TestScore', 'TrainScore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03c4a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_func():\n",
    "    # Inputs\n",
    "    sLength = float(input(\"Enter sepal length: \"))\n",
    "    sWidth = float(input(\"Enter sepal width: \"))\n",
    "    pLength = float(input(\"Enter petal length: \"))\n",
    "    pWidth = float(input(\"Enter petal width: \"))\n",
    "    \n",
    "    # Creating a 2d array from inputs\n",
    "    inpFeatures = np.array([[sLength,sWidth,pLength,pWidth]])\n",
    "    \n",
    "    # Transforming array as we have earlier perform the same\n",
    "    scaledInput = scFeatures.transform(inpFeatures)\n",
    "\n",
    "    # Predicting labeled value from scaled input\n",
    "    predSpecies = (np.argmax(model.predict(scaledInput), axis=-1))\n",
    "\n",
    "    # Fetching the type of flower\n",
    "    flowerType = leSpecies.inverse_transform(predSpecies).item()\n",
    "\n",
    "    print(f\"The Flower having \\n sepal_length: {sLength} \\n sepal_width: {sWidth} \\n petal_length: {pLength} \\n petal_width: {pWidth} \\n represents ==> {flowerType}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a50260dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sepal length: 5.1\n",
      "Enter sepal width: 3.5\n",
      "Enter petal length: 1.2\n",
      "Enter petal width: 0.2\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "The Flower having \n",
      " sepal_length: 5.1 \n",
      " sepal_width: 3.5 \n",
      " petal_length: 1.2 \n",
      " petal_width: 0.2 \n",
      " represents ==> setosa\n"
     ]
    }
   ],
   "source": [
    "prediction_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a715652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter sepal length: 6.2\n",
      "Enter sepal width: 3.4\n",
      "Enter petal length: 5.2\n",
      "Enter petal width: 2.3\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "The Flower having \n",
      " sepal_length: 6.2 \n",
      " sepal_width: 3.4 \n",
      " petal_length: 5.2 \n",
      " petal_width: 2.3 \n",
      " represents ==> virginica\n"
     ]
    }
   ],
   "source": [
    "prediction_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc9bd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd3355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
