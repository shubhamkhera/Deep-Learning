{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d26c67",
   "metadata": {},
   "source": [
    "# Day 3: 3.2\n",
    "\n",
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
    "\n",
    "## Here we are creating an DeepLearning model that can predict wether the customer is a good/bad on the basis of age and salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e820219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c69da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"03_Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79233b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2b4597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c4974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            0\n",
       "Gender             0\n",
       "Age                0\n",
       "EstimatedSalary    0\n",
       "Purchased          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a5d1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    " df = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2e23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c789e0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f12c22be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules of Classification for ML:\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 1d NP array\n",
    "# 6. Normalization of features is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea641df",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c650cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6870a0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef8e1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640625\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "# Check the quality of model\n",
    "# 1. CHeck whether the model is a generalized or not\n",
    "print(log_model.score(X_train,y_train))\n",
    "print(log_model.score(X_test,y_test))\n",
    "\n",
    "# 2. CHeck the quality of model with respect to CL\n",
    "# SL = 0.1\n",
    "# CL = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51e8a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for Deep Learning\n",
    "# 1. Data must be complete\n",
    "# 2. Data must be strictly numeric\n",
    "# 3. Features and Label must be in the form of NumPy array\n",
    "# 4. Features must be a 2d NP array\n",
    "# 5. Label must be 2d NP array\n",
    "# 6. Features must be NORMALIZED\n",
    "# 7. For Binary Classification, label must be represented as 0 / 1 (pd.replace)\n",
    "# 8. For Multi-class classification, label must be  DISCRETE NUMERICAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b6c53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,[2,3]].values\n",
    "label = data.iloc[:,[4]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "844e5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "rbFeatures=RobustScaler()\n",
    "features = rbFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a613aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    label, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10d49961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "# Step1 : Architect the model\n",
    "# step 1.1: Create a Sequential Model\n",
    "\n",
    "seq_model = tf.keras.Sequential()\n",
    "\n",
    "# Step 1.2: Create Dense Layer\n",
    "# units = No. of neurons in Hidden Layer\n",
    "# activation = Which Activation Function to Apply\n",
    "# input_shape = Number of colums in FeatureArray\n",
    "\n",
    "\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1), input_shape = (2,)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=6, activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\n",
    "seq_model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21e67b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "# Step2: Compile the mode:\n",
    "\n",
    "seq_model.compile(optimizer=\"sgd\", loss='binary_crossentropy', metrics=[\"accuracy\", tfa.metrics.F1Score(num_classes=1, threshold=0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c604fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4fe5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyThresholdCallBack(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,cl):\n",
    "        super(MyThresholdCallBack, self).__init__()\n",
    "        self.cl = cl\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        test_score = logs[\"val_accuracy\"]\n",
    "        train_score = logs[\"accuracy\"]\n",
    "        \n",
    "        if test_score > train_score and test_score > self.cl:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa474aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "10/10 [==============================] - 2s 53ms/step - loss: 0.6991 - accuracy: 0.3688 - f1_score: 0.3841 - val_loss: 0.6961 - val_accuracy: 0.4000 - val_f1_score: 0.2258\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6962 - accuracy: 0.3969 - f1_score: 0.1106 - val_loss: 0.6934 - val_accuracy: 0.4750 - val_f1_score: 0.0455\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6936 - accuracy: 0.4625 - f1_score: 0.0227 - val_loss: 0.6908 - val_accuracy: 0.6000 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6911 - accuracy: 0.5469 - f1_score: 0.0000e+00 - val_loss: 0.6883 - val_accuracy: 0.6125 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6888 - accuracy: 0.6281 - f1_score: 0.0000e+00 - val_loss: 0.6859 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6864 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6834 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6835 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6802 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6798 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6760 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6754 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6713 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6708 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6669 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6666 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6628 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6623 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6587 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6583 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6549 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6545 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6514 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6510 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6481 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6477 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6448 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6444 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6418 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6413 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6388 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6383 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6359 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6354 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6332 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6326 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6305 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6300 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6279 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6274 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6254 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.6250 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6229 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6205 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6201 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6181 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6177 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6158 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6153 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6134 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6129 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6111 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6106 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6087 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.6083 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6064 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6059 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6041 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6036 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.6017 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.6012 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5992 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5988 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5968 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5962 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5943 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5937 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5917 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5912 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5893 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5887 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5868 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5862 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5843 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5835 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5817 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5810 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5792 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5784 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5766 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5756 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5740 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5729 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5713 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5702 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5685 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5673 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5657 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5629 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5617 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5600 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5588 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5570 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5558 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5540 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5528 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5509 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5498 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5477 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5444 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5434 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5411 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5402 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5377 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5369 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5343 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.5337 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5308 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5304 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5272 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5268 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5236 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5199 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.5199 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5161 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.5162 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5123 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5126 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5084 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5089 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5045 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5052 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.5006 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5015 - accuracy: 0.6406 - f1_score: 0.0000e+00 - val_loss: 0.4966 - val_accuracy: 0.6500 - val_f1_score: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4977 - accuracy: 0.6438 - f1_score: 0.0172 - val_loss: 0.4925 - val_accuracy: 0.6625 - val_f1_score: 0.0690\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.6438 - f1_score: 0.0172 - val_loss: 0.4884 - val_accuracy: 0.6625 - val_f1_score: 0.0690\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4901 - accuracy: 0.6438 - f1_score: 0.0172 - val_loss: 0.4844 - val_accuracy: 0.6625 - val_f1_score: 0.0690\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4861 - accuracy: 0.6438 - f1_score: 0.0339 - val_loss: 0.4802 - val_accuracy: 0.6750 - val_f1_score: 0.1333\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4822 - accuracy: 0.6469 - f1_score: 0.0504 - val_loss: 0.4760 - val_accuracy: 0.6875 - val_f1_score: 0.1935\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4784 - accuracy: 0.6531 - f1_score: 0.0826 - val_loss: 0.4718 - val_accuracy: 0.6875 - val_f1_score: 0.1935\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4745 - accuracy: 0.6625 - f1_score: 0.1290 - val_loss: 0.4676 - val_accuracy: 0.7000 - val_f1_score: 0.2500\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4706 - accuracy: 0.6656 - f1_score: 0.1575 - val_loss: 0.4632 - val_accuracy: 0.7125 - val_f1_score: 0.3030\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4666 - accuracy: 0.6750 - f1_score: 0.2000 - val_loss: 0.4589 - val_accuracy: 0.7250 - val_f1_score: 0.3529\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4627 - accuracy: 0.6812 - f1_score: 0.2273 - val_loss: 0.4543 - val_accuracy: 0.7250 - val_f1_score: 0.3529\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.6781 - f1_score: 0.2256 - val_loss: 0.4498 - val_accuracy: 0.7250 - val_f1_score: 0.3529\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.6844 - f1_score: 0.2519 - val_loss: 0.4453 - val_accuracy: 0.7375 - val_f1_score: 0.4000\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4507 - accuracy: 0.6906 - f1_score: 0.2878 - val_loss: 0.4407 - val_accuracy: 0.7625 - val_f1_score: 0.4865\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4468 - accuracy: 0.7031 - f1_score: 0.3448 - val_loss: 0.4359 - val_accuracy: 0.7750 - val_f1_score: 0.5263\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4428 - accuracy: 0.7406 - f1_score: 0.4780 - val_loss: 0.4312 - val_accuracy: 0.8250 - val_f1_score: 0.6667\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4387 - accuracy: 0.7688 - f1_score: 0.5595 - val_loss: 0.4265 - val_accuracy: 0.8250 - val_f1_score: 0.6667\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.4349 - accuracy: 0.7781 - f1_score: 0.5848 - val_loss: 0.4219 - val_accuracy: 0.8375 - val_f1_score: 0.6977\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4310 - accuracy: 0.8031 - f1_score: 0.6480 - val_loss: 0.4173 - val_accuracy: 0.8500 - val_f1_score: 0.7391\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4271 - accuracy: 0.8188 - f1_score: 0.6882 - val_loss: 0.4128 - val_accuracy: 0.8500 - val_f1_score: 0.7391\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4234 - accuracy: 0.8313 - f1_score: 0.7158 - val_loss: 0.4083 - val_accuracy: 0.8500 - val_f1_score: 0.7391\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4197 - accuracy: 0.8344 - f1_score: 0.7254 - val_loss: 0.4039 - val_accuracy: 0.8625 - val_f1_score: 0.7755\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8406 - f1_score: 0.7385 - val_loss: 0.3996 - val_accuracy: 0.8500 - val_f1_score: 0.7600\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8406 - f1_score: 0.7437 - val_loss: 0.3953 - val_accuracy: 0.8750 - val_f1_score: 0.8077\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4087 - accuracy: 0.8562 - f1_score: 0.7745 - val_loss: 0.3911 - val_accuracy: 0.8875 - val_f1_score: 0.8302\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4051 - accuracy: 0.8594 - f1_score: 0.7826 - val_loss: 0.3869 - val_accuracy: 0.8875 - val_f1_score: 0.8302\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4016 - accuracy: 0.8656 - f1_score: 0.7962 - val_loss: 0.3829 - val_accuracy: 0.9000 - val_f1_score: 0.8519\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3983 - accuracy: 0.8656 - f1_score: 0.7962 - val_loss: 0.3788 - val_accuracy: 0.9125 - val_f1_score: 0.8727\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3948 - accuracy: 0.8687 - f1_score: 0.8019 - val_loss: 0.3748 - val_accuracy: 0.9125 - val_f1_score: 0.8727\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3916 - accuracy: 0.8625 - f1_score: 0.7944 - val_loss: 0.3708 - val_accuracy: 0.9125 - val_f1_score: 0.8727\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8656 - f1_score: 0.8037 - val_loss: 0.3670 - val_accuracy: 0.9125 - val_f1_score: 0.8727\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3848 - accuracy: 0.8656 - f1_score: 0.8037 - val_loss: 0.3631 - val_accuracy: 0.9125 - val_f1_score: 0.8727\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3816 - accuracy: 0.8625 - f1_score: 0.8000 - val_loss: 0.3594 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3786 - accuracy: 0.8656 - f1_score: 0.8054 - val_loss: 0.3556 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8687 - f1_score: 0.8108 - val_loss: 0.3520 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8750 - f1_score: 0.8214 - val_loss: 0.3484 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3699 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3447 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3669 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3412 - val_accuracy: 0.9000 - val_f1_score: 0.8571\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3642 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3377 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3614 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3343 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3587 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3309 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3276 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3537 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3244 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3514 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3212 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8781 - f1_score: 0.8282 - val_loss: 0.3181 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.8844 - f1_score: 0.8370 - val_loss: 0.3150 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.8781 - f1_score: 0.8282 - val_loss: 0.3120 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.8781 - f1_score: 0.8267 - val_loss: 0.3093 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3405 - accuracy: 0.8813 - f1_score: 0.8333 - val_loss: 0.3065 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8844 - f1_score: 0.8384 - val_loss: 0.3037 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.3367 - accuracy: 0.8844 - f1_score: 0.8384 - val_loss: 0.3011 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3348 - accuracy: 0.8844 - f1_score: 0.8384 - val_loss: 0.2987 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.3328 - accuracy: 0.8844 - f1_score: 0.8384 - val_loss: 0.2963 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8844 - f1_score: 0.8384 - val_loss: 0.2940 - val_accuracy: 0.9125 - val_f1_score: 0.8772\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.3296 - accuracy: 0.8844 - f1_score: 0.8370 - val_loss: 0.2917 - val_accuracy: 0.9250 - val_f1_score: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa51ba3520>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_Threshold = MyThresholdCallBack(cl=0.92)\n",
    "\n",
    "seq_model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test), callbacks=[accuracy_Threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d664f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.8875 - f1_score: 0.8435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32816630601882935, 0.887499988079071, array([0.84347826], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7863d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2917 - accuracy: 0.9250 - f1_score: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2917273938655853, 0.925000011920929, array([0.8965517], dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e804892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(seq_model.predict(features) > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e959accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[235,  22],\n",
       "       [ 20, 123]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(label, (seq_model.predict(features) > 0.5).astype('int32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4a72da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       257\n",
      "           1       0.85      0.86      0.85       143\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.88      0.89      0.89       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, (seq_model.predict(features) > 0.5).astype('int32')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7188165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter age of Customer: 42\n",
      "Enter salary of Customer: 200000\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "The Customer wih 42.0 and salary 200000.0 is going to purchare?: Yes\n"
     ]
    }
   ],
   "source": [
    "# Deployment with Input Example:\n",
    "\n",
    "# 1. Getting user input in the form of float\n",
    "ageInYears = float(input(\"Enter age of Customer: \"))\n",
    "salaryCust = float(input(\"Enter salary of Customer: \"))\n",
    "\n",
    "# 2. Converting input to 2d array since the same format was used for training this model\n",
    "custArray = np.array([[ageInYears, salaryCust]])\n",
    "\n",
    "# 3. Apply Standardization scince the same was done during the training of model\n",
    "scaledCustData = rbFeatures.transform(custArray)\n",
    "\n",
    "# 4. Predicting the salary\n",
    "#purchase = seq_model.predict(scaledCustData)\n",
    "\n",
    "# 5. Inverse Transform Label\n",
    "actualPurch = ((seq_model.predict(scaledCustData) > 0.5).astype('int32')).item()\n",
    "\n",
    "def final_rep(x):\n",
    "    if actualPurch == 0:\n",
    "        return \"No\"\n",
    "    if actualPurch == 1:\n",
    "        return \"Yes\"\n",
    "\n",
    "print(f\"The Customer wih {ageInYears} and salary {salaryCust} is going to purchare?: {final_rep(actualPurch)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4dc655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231, -1.11111111]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaledCustData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303f8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
