{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d6e4c75",
   "metadata": {},
   "source": [
    "# Day 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c4a23",
   "metadata": {},
   "source": [
    "## XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f2bb6",
   "metadata": {},
   "source": [
    "### Training of a Neural Network:\n",
    "**Steps:**\n",
    "1. **Forward Propagation**\n",
    "2. **Error Calculation**\n",
    "3. **Backward Propagation** (Goal is to update weights and bias such that training is successful and reduces the error)\n",
    "\n",
    "\n",
    "Example: Consider a dataset containing 1 record\n",
    "- wx1(Input * weight) = 0.3\n",
    "- b(bias) = 0\n",
    "- a(activation Function) = Sigmoid\n",
    "- Error Function = MeanSquaredError\n",
    "\n",
    "As we move with the process we first per form the **FORWARD PROPAGATION** i.e., **sum(wixi) where i = 1 to n => 0.3** Moving ahead we apply a **sigmoid function** as **activation function i.e.,1/(1 + e^z) => 0.5744** now we will apply **ERROR FUNCTION** **MeanSquaredError i.e., sum(Yi - Yipred)/n where i = 1 to n**. Movingahead we will perform **BACK PROPAGATION**.\n",
    "\n",
    "**Back Propagation(Geoffrey Hinton):**\n",
    "- *Goal: Minimize the error abd Converge the model*\n",
    "\n",
    "Input layer -----> Set of Hidden Layers ------> Output Layer\n",
    "\n",
    "Given:\n",
    "D - Dataset\n",
    "X - Record/Tuple in a dataset\n",
    "L - Learning rates\n",
    "activation fn - sigmoid\n",
    "\n",
    "Algorithm:\n",
    "- Initialize(Randomly or algo based etc.) all weights and bias in the network\n",
    "- While terminating condition is not satisfied:\n",
    "    - for each training tuple X in dataset D:\n",
    "        1. ***Forward Propagation***\n",
    "        - if input_layer:\n",
    "            - Oj = Ij\n",
    "        - if hidden_layer:\n",
    "            - Ij = sum(WijOi + θi)  _____________  θ ----> bias\n",
    "            - Oj = 1/1+e^Ij\n",
    "        2. ***Error Calculation***\n",
    "        - for each neuron j in output the layer:\n",
    "            - Error(j) = Oj(1 - Oj)(Tj - Oj)   _______   Tj -----> actual y  ___________    Oj -----> predicted y\n",
    "        - for each neuron j in the hidden layer:\n",
    "            - Error(j) = Oj(1-Oj) sum(Err(k)Wjk)\n",
    "        3. ***Updated weights and Bias(Back Propagation)***\n",
    "        - for each weight Wij in network:\n",
    "            - ΔWij = L * Err(j) * Oi\n",
    "            - Wij = Wij + ΔWij\n",
    "        - for each bias θj in network:\n",
    "            - Δθj = L * Err(j)\n",
    "            - θj = θj + Δθj\n",
    "            \n",
    "***Note: The full iteration above i.e., 1. Forward Propagation, 2. Error calculation, and 3.Back Propagation is called EPOCH***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb0307",
   "metadata": {},
   "source": [
    "## Optimizers:\n",
    "\n",
    "- **The Optimizers are used for Back Propagation**\n",
    "- **Optimizers:**\n",
    "    - Adadelta\n",
    "    - Adagrad\n",
    "    - Adam\n",
    "    - Adamax\n",
    "    - FTRL\n",
    "    - Nadam\n",
    "    - RMSprop\n",
    "    - SGD (Sochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cb1e96",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb70ac8",
   "metadata": {},
   "source": [
    "## How We create a Neural Network in Python:\n",
    "\n",
    "- **model = tf.keras.Sequential()**\n",
    "- **model.add(tf.keras.Dense(units = 8, activation = 'sigmoid'))**\n",
    "- **model.add(tf.keras.Dense(units = 1, activation = 'sigmoid'))**\n",
    "- **model.compile(optimizer = 'sgd, loss = 'mse')**\n",
    "- **model.fit(x, y, batch_size = 32, epochs=10)**\n",
    "\n",
    "\n",
    "**Above just an example how the model is create it is not following any hard and fast rules**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b2b99f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0aeb266d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24846c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df6b6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf20b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b9713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43deb014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c80694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
