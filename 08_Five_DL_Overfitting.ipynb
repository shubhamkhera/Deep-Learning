{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eddfeb0",
   "metadata": {},
   "source": [
    "# Day 5:\n",
    "\n",
    "1. Dealing with Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438eabc8",
   "metadata": {},
   "source": [
    "1. Neural Network tends to OVERFIT !!!!\n",
    "\n",
    "2. How to Deal with Overfitting?\n",
    "    - Dealing with overfitting is reactive activity. There is no Proactive stratergy available to work with Overfitting.\n",
    "        1. Try Changing the weight and Bias Initialization Algorithm/ Formula\n",
    "            - Dense\n",
    "                - tf.keras.layers.Dense( \n",
    "                - kernal_initializer = 'glorot_uniform'     --------> This is used to initialize weights in Epoch1\n",
    "                - bias_initializer= 'zeros')       --------> This is used to initialize bias in Epoch1\n",
    "            \n",
    "            - Formulas available for weights and bias (initializers)\n",
    "        2. Try changing the Backpropagation Algorithm. (Explore optimizers package in tf.keras )\n",
    "           - SGD ( Stochastic Gradient Descent )\n",
    "           - and many more\n",
    "        3. Try Changing the learning Rate Hyperparameter for each Backpropagation Algorithm (LR is static fro entire Epoch Iteration)\n",
    "            - LRate ---- Range ---- 0 to 1 (stepSize suggested is -->0.001)\n",
    "                - SGD\n",
    "                - AdaDelta\n",
    "                - AdaGrad\n",
    "                - Adam\n",
    "                - Ftrl\n",
    "                - Nadam\n",
    "                - RMSProp\n",
    "        4. Try Optimizing the Learning Rate Dynamically ( Changing LR after every epoch )\n",
    "            - optimizers.schedules\n",
    "        5. Try Changing Regularization\n",
    "             - Dense\n",
    "                 - kernel_regularizer=\n",
    "                 - bias_regularizer=\n",
    "             - regularizers\n",
    "        6. Try Changing the momentum ( Momentum is also a hyper parameter that decides the speed of the training time )\n",
    "            - Momentum parameter is a part of Optimizers Algorithms. Following has momentum parameters\n",
    "        7. Try Dropout\n",
    "        8. Ask for more DATA\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb77e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e61c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/639388c2cbc2120a14dcf466e85730eb8be498bb/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d21ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "502b2b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,:-1]\n",
    "label = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe329d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scFeatures = StandardScaler()\n",
    "features = scFeatures.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd5a4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "leLabel = LabelEncoder()\n",
    "label = leLabel.fit_transform(label)\n",
    "\n",
    "kerasLabelCat = tf.keras.utils.to_categorical(label)\n",
    "kerasLabelCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb960cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    kerasLabelCat, \n",
    "                                                    test_size= 0.2, \n",
    "                                                    random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c682ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step:1 Create a Sequential Model\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Step2: Create Dense Layes with usints, activation and input shape\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu', input_shape=(4,)))  # Input Layer\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 1\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 2\n",
    "model.add(tf.keras.layers.Dense(units= 12, activation= 'relu'))  # Hidden Layer 3\n",
    "\n",
    "# Number of units in output layer for multi-class classification is equal to the no. of unique labels \n",
    "model.add(tf.keras.layers.Dense(units= 3, activation= 'softmax'))  # Output Layer\n",
    "\n",
    "# Compile The model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad80ca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 1s 92ms/step - loss: 1.0710 - accuracy: 0.4500 - val_loss: 1.1055 - val_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0573 - accuracy: 0.5000 - val_loss: 1.0999 - val_accuracy: 0.4333\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0465 - accuracy: 0.5750 - val_loss: 1.0933 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.0355 - accuracy: 0.5917 - val_loss: 1.0872 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0258 - accuracy: 0.6000 - val_loss: 1.0815 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0170 - accuracy: 0.6167 - val_loss: 1.0761 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0087 - accuracy: 0.6167 - val_loss: 1.0708 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0006 - accuracy: 0.6250 - val_loss: 1.0654 - val_accuracy: 0.5333\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9931 - accuracy: 0.6417 - val_loss: 1.0602 - val_accuracy: 0.5667\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9856 - accuracy: 0.6583 - val_loss: 1.0550 - val_accuracy: 0.5667\n"
     ]
    }
   ],
   "source": [
    "M1 = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6bd3f",
   "metadata": {},
   "source": [
    "1. Try Changing the weight and Bias Initialization Algorithm/ Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c57cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454c93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e82127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f42933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4f6954",
   "metadata": {},
   "source": [
    "2. Try changing the Backpropagation Algorithm. (Explore optimizers package in tf.keras )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9fbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f425d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f34f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "200d0e2b",
   "metadata": {},
   "source": [
    "3. Try Changing the learning Rate Hyperparameter for each Backpropagation Algorithm (LR is static fro entire Epoch Iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195376b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089d9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821fe31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42428336",
   "metadata": {},
   "source": [
    "4. Try Optimizing the Learning Rate Dynamically ( Changing LR after every epoch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a42f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ab7253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71734a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb28f68e",
   "metadata": {},
   "source": [
    "5. Try Changing Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c26b421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7e6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f19b278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fc83894",
   "metadata": {},
   "source": [
    "6. Try Changing the momentum ( Momentum is also a hyper parameter that decides the speed of the training time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694653b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e88005b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "134a1fd7",
   "metadata": {},
   "source": [
    "7. Try Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba73e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a5795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7dfeaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
