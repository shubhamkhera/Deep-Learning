{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a651068",
   "metadata": {},
   "source": [
    "# Day 5:\n",
    "\n",
    "1. Dealing with Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457bcaa",
   "metadata": {},
   "source": [
    "1. Neural Network tends to OVERFIT !!!!\n",
    "\n",
    "2. How to Deal with Overfitting?\n",
    "    - Dealing with overfitting is reactive activity. There is no Proactive stratergy available to work with Overfitting.\n",
    "        1. Try Changing the weight and Bias Initialization Algorithm/ Formula\n",
    "            - Dense\n",
    "                - tf.keras.layers.Dense( \n",
    "                - kernal_initializer = 'glorot_uniform'     --------> This is used to initialize weights in Epoch1\n",
    "                - bias_initializer= 'zeros')       --------> This is used to initialize bias in Epoch1\n",
    "            \n",
    "            - Formulas available for weights and bias (initializers)\n",
    "        2. TRry changing the Backpropagation Algorithm. (Explore optimizers package in tf.keras )\n",
    "           - SGD ( Stochastic Gradient Descent )\n",
    "           - and many more\n",
    "        3. Try Changing the learning Rate Hyperparameter for each Backpropagation Algorithm (LR is static fro entire Epoch Iteration)\n",
    "            - LRate ---- Range ---- 0 to 1 (stepSize suggested is -->0.001)\n",
    "                - SGD\n",
    "                - AdaDelta\n",
    "                - AdaGrad\n",
    "                - Adam\n",
    "                - Ftrl\n",
    "                - Nadam\n",
    "                - RMSProp\n",
    "        4. Try Optimizing the Learning Rate Dynamically ( Changing LR after every epoch )\n",
    "            - optimizers.schedules\n",
    "        5. Try Changing Regularization\n",
    "             - Dense\n",
    "                 - kernel_regularizer=\n",
    "                 - bias_regularizer=\n",
    "             - regularizers\n",
    "        6. Try Changing the momentum ( Momentum is also a hyper parameter that decides the speed of the training time )\n",
    "            - Momentum parameter is a part of Optimizers Algorithms. Following has momentum parameters\n",
    "        7. TRy Dropout\n",
    "        8. Ask for more DATA\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece850d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065d342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7893497f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84641cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
